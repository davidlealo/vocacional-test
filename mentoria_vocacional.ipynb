{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNbuDqwEQQMwnicrfFoJPrH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/vocacional-test/blob/main/mentoria_vocacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicaci√≥n del C√≥digo de Mentoria Vocacional\n",
        "\n",
        "Este documento describe un cuaderno Jupyter (`mentoria_vocacional.ipynb`) dise√±ado para implementar un sistema de mentor√≠a pedag√≥gica utilizando Azure Cognitive Search y Azure OpenAI. A continuaci√≥n, se detalla cada secci√≥n del c√≥digo, explicando su prop√≥sito y funcionalidad.\n",
        "\n",
        "## 1. Instalaci√≥n de Dependencias\n",
        "\n",
        "```python\n",
        "!pip install python-dotenv requests openai --upgrade\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Instala las bibliotecas necesarias para ejecutar el c√≥digo.\n",
        "- **Detalles**:\n",
        "  - `python-dotenv`: Permite cargar variables de entorno desde un archivo `.env`.\n",
        "  - `requests`: Facilita realizar solicitudes HTTP a la API de Azure Search.\n",
        "  - `openai`: Proporciona acceso a la API de Azure OpenAI para interactuar con modelos de lenguaje.\n",
        "  - El flag `--upgrade` asegura que se instalen las versiones m√°s recientes de estas bibliotecas.\n",
        "\n",
        "**Salida**:\n",
        "Muestra la instalaci√≥n exitosa de las dependencias y sus versiones, junto con las subdependencias requeridas (como `charset_normalizer`, `idna`, etc.).\n",
        "\n",
        "## 2. Carga de Variables de Entorno\n",
        "\n",
        "```python\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "import requests\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "AZURE_SEARCH_API_KEY = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "AZURE_SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
        "AZURE_SEARCH_INDEX_NAME = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "\n",
        "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Configura el entorno cargando credenciales y configuraciones desde un archivo `.env`.\n",
        "- **Detalles**:\n",
        "  - `load_dotenv()` lee las variables de entorno desde el archivo `.env`.\n",
        "  - Se asignan variables para:\n",
        "    - **Azure Cognitive Search**: Clave API (`AZURE_SEARCH_API_KEY`), endpoint (`AZURE_SEARCH_ENDPOINT`) y nombre del √≠ndice (`AZURE_SEARCH_INDEX_NAME`).\n",
        "    - **Azure OpenAI**: Clave API (`AZURE_OPENAI_API_KEY`), endpoint (`AZURE_OPENAI_ENDPOINT`) y nombre del despliegue del modelo (`AZURE_OPENAI_DEPLOYMENT_NAME`).\n",
        "  - Estas variables son esenciales para autenticar y conectar con los servicios de Azure.\n",
        "\n",
        "## 3. Funci√≥n para Buscar Documentos en Azure Search\n",
        "\n",
        "```python\n",
        "def search_documents(query, top_k=5):\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": AZURE_SEARCH_API_KEY\n",
        "    }\n",
        "    payload = {\n",
        "        \"search\": query,\n",
        "        \"top\": top_k\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    results = response.json()\n",
        "    return [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Realiza una b√∫squeda de documentos en Azure Cognitive Search basada en una consulta de texto.\n",
        "- **Detalles**:\n",
        "  - **Par√°metros**:\n",
        "    - `query`: Texto de la consulta de b√∫squeda.\n",
        "    - `top_k`: N√∫mero m√°ximo de documentos a recuperar (por defecto, 5).\n",
        "  - Construye una URL para la API de Azure Search utilizando el endpoint y el nombre del √≠ndice.\n",
        "  - Configura los encabezados HTTP con el tipo de contenido (`application/json`) y la clave API.\n",
        "  - Env√≠a una solicitud POST con un cuerpo JSON que incluye la consulta (`search`) y el l√≠mite de resultados (`top`).\n",
        "  - Maneja errores con `raise_for_status()` y devuelve una lista con el contenido (`content`) de los documentos recuperados.\n",
        "  - Si el campo `content` no existe en un documento, se devuelve una cadena vac√≠a.\n",
        "\n",
        "**Variante con Depuraci√≥n**:\n",
        "En una celda posterior, se modifica esta funci√≥n para incluir depuraci√≥n:\n",
        "\n",
        "```python\n",
        "def search_documents(query, top_k=10):\n",
        "    ...\n",
        "    for doc in results.get(\"value\", []):\n",
        "        print(\"Campos disponibles:\", doc.keys())\n",
        "        break\n",
        "    return [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "```\n",
        "\n",
        "- **Cambios**:\n",
        "  - Aumenta `top_k` a 10 por defecto.\n",
        "  - Imprime las claves de los documentos recuperados para inspeccionar los campos disponibles (como `@search.score`, `chunk_id`, `parent_id`, `chunk`, `title`, `text_vector`).\n",
        "  - Opcionalmente, permite usar b√∫squeda sem√°ntica (comentada) con `\"queryType\": \"semantic\"`.\n",
        "\n",
        "## 4. Configuraci√≥n del Cliente de Azure OpenAI\n",
        "\n",
        "```python\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-08-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Inicializa el cliente para interactuar con el modelo de Azure OpenAI (Phi-4).\n",
        "- **Detalles**:\n",
        "  - Usa la clave API, la versi√≥n de la API (`2023-08-01-preview`) y el endpoint configurados previamente.\n",
        "  - Este cliente se utiliza para generar respuestas basadas en prompts.\n",
        "\n",
        "## 5. Funci√≥n para Generar Respuestas con Contexto\n",
        "\n",
        "```python\n",
        "def generate_answer(question, context):\n",
        "    system_prompt = \"Eres un mentor pedag√≥gico. Responde de forma clara, breve y √∫til basado en el contexto.\"\n",
        "    user_prompt = f\"Pregunta: {question}\\n\\nContexto:\\n{context}\"\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Genera una respuesta utilizando el modelo de Azure OpenAI, combinando una pregunta y un contexto recuperado.\n",
        "- **Detalles**:\n",
        "  - **Par√°metros**:\n",
        "    - `question`: La pregunta del usuario.\n",
        "    - `context`: Texto recuperado de Azure Search.\n",
        "  - Define un `system_prompt` que instruye al modelo a actuar como un mentor pedag√≥gico, proporcionando respuestas claras y √∫tiles.\n",
        "  - Construye un `user_prompt` que incluye la pregunta y el contexto.\n",
        "  - Llama a la API de chat completions con:\n",
        "    - El nombre del despliegue del modelo.\n",
        "    - Una lista de mensajes (system y user).\n",
        "    - Configuraciones: `temperature=0.3` (para respuestas m√°s deterministas) y `max_tokens=500` (l√≠mite de tokens en la respuesta).\n",
        "  - Devuelve el contenido de la primera opci√≥n de la respuesta generada.\n",
        "\n",
        "## 6. Ejecuci√≥n de Ejemplos\n",
        "\n",
        "El c√≥digo incluye varias celdas que prueban el sistema con diferentes preguntas. A continuaci√≥n, se describen los casos de uso:\n",
        "\n",
        "### Ejemplo 1: Pregunta sobre Valentina y el Financiamiento de la Educaci√≥n\n",
        "\n",
        "```python\n",
        "pregunta = \"¬øQu√© dijo Valentina sobre el financiamiento de la educaci√≥n?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "print(\"Respuesta del asistente:\\n\", respuesta)\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Busca documentos relacionados con la pregunta y genera una respuesta.\n",
        "- **Salida**:\n",
        "  - Los documentos recuperados est√°n vac√≠os, por lo que la respuesta indica que falta contexto:  \n",
        "    _\"Parece que no has proporcionado el contexto espec√≠fico en el que Valentina habl√≥ sobre el financiamiento de la educaci√≥n...\"_\n",
        "\n",
        "### Ejemplo 2: Pregunta sobre Desaf√≠os de Estudiantes Rurales seg√∫n David\n",
        "\n",
        "```python\n",
        "pregunta = \"¬øQu√© desaf√≠os enfrentan los estudiantes en zonas rurales seg√∫n David?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "print(\"Respuesta del asistente:\\n\", respuesta)\n",
        "```\n",
        "\n",
        "- **Salida**: Similar al ejemplo anterior, no se encuentra contexto relevante, y la respuesta solicita m√°s informaci√≥n:  \n",
        "  _\"Lamento, pero no puedo proporcionar una respuesta directa a tu pregunta ya que no has proporcionado el contexto o el texto en el que se menciona a David...\"_\n",
        "\n",
        "### Ejemplo 3: Pregunta sobre `proyectate.info`\n",
        "\n",
        "```python\n",
        "pregunta = \"¬øQu√© es proyectate.info?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "print(\"Respuesta del asistente:\\n\", respuesta)\n",
        "```\n",
        "\n",
        "- **Salida**: No se encuentra informaci√≥n sobre `proyectate.info`, y la respuesta refleja esto:  \n",
        "  _\"Parece que te refieres a 'projectate.info', pero no tengo informaci√≥n espec√≠fica sobre un sitio web o recurso con ese nombre...\"_\n",
        "\n",
        "### Ejemplo 4: Pregunta sobre P√©rdida de Beneficios del Cr√©dito Universitario\n",
        "\n",
        "```python\n",
        "pregunta = \"¬øQu√© debo hacer si perd√≠ mis beneficios del cr√©dito universitario?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "print(\"\\n--- Documentos recuperados ---\")\n",
        "print(contexto[:1000])\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "print(\"\\n--- Respuesta del asistente ---\")\n",
        "print(respuesta)\n",
        "```\n",
        "\n",
        "- **Salida**:\n",
        "  - Los documentos recuperados est√°n vac√≠os, pero el modelo genera una respuesta general basada en conocimiento impl√≠cito, sugiriendo pasos como contactar al Centro de Ayuda Estudiantil, revisar informes de cr√©dito, y buscar asesor√≠a legal.\n",
        "  - Esto indica que el modelo puede proporcionar respuestas √∫tiles incluso sin contexto espec√≠fico, aunque no se basa en documentos recuperados.\n",
        "\n",
        "### Ejemplo 5: M√∫ltiples Preguntas en un Bucle\n",
        "\n",
        "```python\n",
        "preguntas = [\n",
        "    \"¬øQu√© es Proyectate?\",\n",
        "    \"¬øQu√© dijo Valentina sobre el cr√©dito universitario?\",\n",
        "    \"¬øQu√© recomendaci√≥n dio David a los estudiantes rurales?\"\n",
        "]\n",
        "for pregunta in preguntas:\n",
        "    print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "    documentos = search_documents(pregunta)\n",
        "    contexto = \"\\n\\n\".join(documentos)\n",
        "    respuesta = generate_answer(pregunta, contexto)\n",
        "    print(\"Respuesta:\", respuesta)\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Procesa m√∫ltiples preguntas en un bucle, mostrando los resultados de cada una.\n",
        "- **Salida**:\n",
        "  - Todas las respuestas indican falta de contexto, solicitando m√°s informaci√≥n para proporcionar respuestas precisas.\n",
        "  - Esto sugiere que el √≠ndice de Azure Search no contiene documentos relevantes para estas preguntas.\n",
        "\n",
        "### Ejemplo 6: Preguntas sobre Personas y el Chat de IA\n",
        "\n",
        "```python\n",
        "preguntas = [\n",
        "    \"Qui√©n es Valentina Gran de Fundaci√≥n Por Una Carrera?\",\n",
        "    \"Qui√©n es David Leal de Innovacien?\",\n",
        "    \"¬øQu√© es el chat de Inteligencia artificial que se present√≥ en la conversaci√≥n?\"\n",
        "]\n",
        "for pregunta in preguntas:\n",
        "    print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "    documentos = search_documents(pregunta)\n",
        "    contexto = \"\\n\\n\".join(documentos)\n",
        "    respuesta = generate_answer(pregunta, contexto)\n",
        "    print(\"Respuesta:\", respuesta)\n",
        "```\n",
        "\n",
        "- **Salida**:\n",
        "  - **Valentina Gran**: Se describe como una defensora de la igualdad de g√©nero y fundadora de Fundaci√≥n Por Una Carrera, con detalles sobre su trabajo desde 2006.\n",
        "  - **David Leal**: Identificado como CEO de Innovacien, una startup de IA, con √©nfasis en su liderazgo en transformaci√≥n digital.\n",
        "  - **Chat de IA**: No se encuentra contexto, y la respuesta solicita m√°s detalles sobre la conversaci√≥n referida.\n",
        "  - **Nota**: Las respuestas sobre Valentina y David parecen basarse en conocimiento del modelo, no en documentos recuperados, ya que el contexto est√° vac√≠o.\n",
        "\n",
        "## 7. Funciones para B√∫squeda con Vectores\n",
        "\n",
        "### Generaci√≥n de Embeddings\n",
        "\n",
        "```python\n",
        "def get_query_embedding(text):\n",
        "    response = client.embeddings.create(\n",
        "        model=os.environ[\"AZURE_OPENAI_EMBEDDING\"],\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Genera un embedding (vector num√©rico) para un texto dado usando un modelo de embeddings de Azure OpenAI.\n",
        "- **Detalles**:\n",
        "  - Usa la variable de entorno `AZURE_OPENAI_EMBEDDING` para especificar el modelo de embeddings.\n",
        "  - Toma un texto (`text`) como entrada y devuelve su representaci√≥n vectorial.\n",
        "\n",
        "### B√∫squeda con Vectores\n",
        "\n",
        "```python\n",
        "def search_documents_with_vectors(query, top_k=3):\n",
        "    embedding = get_query_embedding(query)\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": AZURE_SEARCH_API_KEY\n",
        "    }\n",
        "    payload = {\n",
        "        \"vectorQueries\": [\n",
        "            {\n",
        "                \"vector\": embedding,\n",
        "                \"k\": top_k,\n",
        "                \"fields\": \"content\"\n",
        "            }\n",
        "        ],\n",
        "        \"select\": \"content,source,@search.score\"\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    results = response.json()\n",
        "    return [doc[\"content\"] for doc in results.get(\"value\", [])]\n",
        "```\n",
        "\n",
        "- **Prop√≥sito**: Realiza una b√∫squeda basada en vectores en Azure Search, utilizando el embedding de la consulta.\n",
        "- **Detalles**:\n",
        "  - Genera el embedding de la consulta con `get_query_embedding`.\n",
        "  - Construye una solicitud a Azure Search con un `vectorQueries` que incluye:\n",
        "    - El vector de la consulta (`vector`).\n",
        "    - El n√∫mero de resultados a recuperar (`k`, por defecto 3).\n",
        "    - El campo a buscar (`fields: content`).\n",
        "  - Especifica los campos a devolver (`select: content,source,@search.score`).\n",
        "  - Devuelve una lista con el contenido de los documentos recuperados.\n",
        "- **Nota**: Esta funci√≥n no se utiliza en los ejemplos proporcionados, pero est√° dise√±ada para b√∫squedas sem√°nticas m√°s avanzadas.\n",
        "\n",
        "## Observaciones Generales\n",
        "\n",
        "- **Estructura**: El cuaderno est√° organizado en celdas que progresivamente configuran el entorno, definen funciones y ejecutan ejemplos.\n",
        "- **Dependencias de Azure**: El c√≥digo depende de servicios de Azure (Cognitive Search y OpenAI), requiriendo credenciales v√°lidas y un √≠ndice poblado.\n",
        "- **Limitaciones Observadas**:\n",
        "  - En la mayor√≠a de los ejemplos, los documentos recuperados est√°n vac√≠os, lo que sugiere que el √≠ndice de Azure Search no contiene datos relevantes o que las consultas no coinciden con el contenido indexado.\n",
        "  - Las respuestas generadas a menudo se basan en el conocimiento del modelo en lugar de los documentos recuperados.\n",
        "- **Depuraci√≥n**: La inclusi√≥n de `print(\"Campos disponibles:\", doc.keys())` ayuda a inspeccionar la estructura de los documentos, revelando campos como `chunk` y `text_vector`, aunque el c√≥digo usa `content`.\n",
        "\n"
      ],
      "metadata": {
        "id": "GqhBoVeGwQax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias (solo una vez)\n",
        "!pip install python-dotenv requests openai --upgrade\n",
        "\n",
        "# ========================\n",
        "# 1. Cargar variables del entorno\n",
        "# ========================\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "import requests\n",
        "\n",
        "load_dotenv()  # Aseg√∫rate de haber subido el archivo .env\n",
        "\n",
        "# Azure Search\n",
        "AZURE_SEARCH_API_KEY = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "AZURE_SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
        "AZURE_SEARCH_INDEX_NAME = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "\n",
        "# Azure OpenAI\n",
        "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "\n",
        "# ========================\n",
        "# 2. Buscar documentos en Azure Search\n",
        "# ========================\n",
        "def search_documents(query, top_k=5):\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": AZURE_SEARCH_API_KEY\n",
        "    }\n",
        "    payload = {\n",
        "        \"search\": query,\n",
        "        \"top\": top_k\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    results = response.json()\n",
        "    return [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "\n",
        "# ========================\n",
        "# 3. Llamar a Phi-4 con contexto\n",
        "# ========================\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-08-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "\n",
        "def generate_answer(question, context):\n",
        "    system_prompt = \"Eres un mentor pedag√≥gico. Responde de forma clara, breve y √∫til basado en el contexto.\"\n",
        "    user_prompt = f\"Pregunta: {question}\\n\\nContexto:\\n{context}\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKR_vUuielGm",
        "outputId": "9cb26e9f-8b89-465e-f9dc-fee21d17aa87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.7.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"¬øQu√© dijo Valentina sobre el financiamiento de la educaci√≥n?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "\n",
        "print(\"Respuesta del asistente:\\n\", respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjby-F_zeqJT",
        "outputId": "c21cff87-6817-4f2e-d231-e14b9d557a41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respuesta del asistente:\n",
            " Parece que no has proporcionado el contexto espec√≠fico en el que Valentina habl√≥ sobre el financiamiento de la educaci√≥n. Si puedes proporcionar m√°s detalles o el texto completo donde se menciona, estar√© encantado de ayudarte a resumir o responder a tu pregunta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambia aqu√≠ tu nueva pregunta\n",
        "pregunta = \"¬øQu√© desaf√≠os enfrentan los estudiantes en zonas rurales seg√∫n David?\"\n",
        "\n",
        "# Ejecuta las funciones con la nueva pregunta\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "\n",
        "print(\"Respuesta del asistente:\\n\", respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erg0Sazbg9zN",
        "outputId": "cde64a83-6dbc-4875-c707-65e0ea8ded6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respuesta del asistente:\n",
            " Lamento, pero no puedo proporcionar una respuesta directa a tu pregunta ya que no has proporcionado el contexto o el texto en el que se menciona a David. Por favor, proporci√≥name el contexto o el texto espec√≠fico donde David discute los desaf√≠os que enfrentan los estudiantes en zonas rurales. ¬°Gracias!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambia aqu√≠ tu nueva pregunta\n",
        "pregunta = \"¬øQu√© es proyectate.info?\"\n",
        "\n",
        "# Ejecuta las funciones con la nueva pregunta\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "\n",
        "print(\"Respuesta del asistente:\\n\", respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gusKUIRxhB9N",
        "outputId": "55d29c00-5161-455d-cd41-138fef5cf7a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respuesta del asistente:\n",
            " Parece que te refieres a \"projectate.info\", pero no tengo informaci√≥n espec√≠fica sobre un sitio web o recurso con ese nombre. Es posible que sea un sitio web menos conocido, un sitio personal, una p√°gina de proyecto o algo similar. Si tienes m√°s contexto o detalles, ¬°puedo intentar ayudarte mejor! Por favor, proporciona m√°s informaci√≥n o aclara tu pregunta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Documentos encontrados:\\n\", contexto)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcf2MXGkh6he",
        "outputId": "3cd5af20-1ee3-4304-ccc3-c0534848e937"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos encontrados:\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Instalar dependencias (si no lo hiciste) ===\n",
        "# !pip install python-dotenv requests openai --upgrade\n",
        "\n",
        "# === 2. Cargar variables de entorno ===\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "import requests\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Azure Cognitive Search\n",
        "AZURE_SEARCH_API_KEY = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "AZURE_SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
        "AZURE_SEARCH_INDEX_NAME = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "\n",
        "# Azure OpenAI (Phi-4)\n",
        "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "\n",
        "# === 3. Buscar documentos en Azure Search ===\n",
        "def search_documents(query, top_k=10):\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": AZURE_SEARCH_API_KEY\n",
        "    }\n",
        "    payload = {\n",
        "        \"search\": query,\n",
        "        \"top\": top_k,\n",
        "        \"queryType\": \"simple\",  # Puedes probar \"semantic\" si lo activas en Azure\n",
        "        # \"semanticConfiguration\": \"default\",  # si activas b√∫squeda sem√°ntica\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    results = response.json()\n",
        "\n",
        "    # Mostrar claves disponibles por documento para verificar campo correcto\n",
        "    for doc in results.get(\"value\", []):\n",
        "        print(\"Campos disponibles:\", doc.keys())\n",
        "        break\n",
        "\n",
        "    # Cambia \"content\" por el campo correcto si es necesario (ej. \"text\", \"chunk\", \"transcription\")\n",
        "    return [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "\n",
        "# === 4. Llamar a Phi-4 con contexto ===\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-08-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "\n",
        "def generate_answer(question, context):\n",
        "    system_prompt = \"Eres un mentor pedag√≥gico. Responde de forma clara, breve y √∫til basado en el contexto.\"\n",
        "    user_prompt = f\"Pregunta: {question}\\n\\nContexto:\\n{context}\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# === 5. Ejecutar ejemplo ===\n",
        "pregunta = \"¬øQu√© dijo Valentina sobre el financiamiento de la educaci√≥n?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "\n",
        "print(\"\\n--- Documentos recuperados ---\")\n",
        "print(contexto[:1000])  # Muestra los primeros 1000 caracteres del contexto\n",
        "\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "\n",
        "print(\"\\n--- Respuesta del asistente ---\")\n",
        "print(respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju-i2jVXilL6",
        "outputId": "69efcfd4-4488-4b03-d6f5-afd85c7f2eca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "\n",
            "--- Documentos recuperados ---\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--- Respuesta del asistente ---\n",
            "Lo siento, pero no puedo proporcionar la informaci√≥n que est√°s buscando porque no tengo el contexto o el texto espec√≠fico en el que Valentina podr√≠a haber hablado sobre el financiamiento de la educaci√≥n. Si puedes proporcionar m√°s detalles o el texto espec√≠fico, estar√© encantado de ayudarte a analizarlo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5. Ejecutar ejemplo ===\n",
        "pregunta = \"¬øQu√© debo hacer si perd√≠ mis beneficios del credito universitario?\"\n",
        "documentos = search_documents(pregunta)\n",
        "contexto = \"\\n\\n\".join(documentos)\n",
        "\n",
        "print(\"\\n--- Documentos recuperados ---\")\n",
        "print(contexto[:1000])  # Muestra los primeros 1000 caracteres del contexto\n",
        "\n",
        "respuesta = generate_answer(pregunta, contexto)\n",
        "\n",
        "print(\"\\n--- Respuesta del asistente ---\")\n",
        "print(respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWn4dixAjK5Z",
        "outputId": "c56fe757-6e43-415e-cbba-28391debaa24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "\n",
            "--- Documentos recuperados ---\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--- Respuesta del asistente ---\n",
            "Si has perdido tus beneficios del cr√©dito universitario, es importante actuar r√°pidamente para resolver el problema. Aqu√≠ hay algunos pasos que puedes seguir:\n",
            "\n",
            "1. **Contacta al Centro de Ayuda Estudiantil (EAC) de tu universidad**: El EAC es el primer punto de contacto para problemas relacionados con el cr√©dito universitario. Ellos pueden proporcionarte informaci√≥n espec√≠fica sobre tu situaci√≥n y guiarte sobre los pasos a seguir.\n",
            "\n",
            "2. **Revisa tu informaci√≥n de cr√©dito**: Verifica tu informaci√≥n de cr√©dito para asegurarte de que los cambios se reflejen correctamente. Si hay errores, puedes solicitar una correcci√≥n.\n",
            "\n",
            "3. **Revisa tu informaci√≥n de identidad**: Aseg√∫rate de que tus datos de identidad sean correctos en las bases de datos del EAC. Cualquier discrepancia podr√≠a causar problemas con tu cr√©dito.\n",
            "\n",
            "4. **Solicita una copia de tu informe de cr√©dito**: Obt√©n copias de tus informes de cr√©dito de las tres principales agencias de cr√©dito (Experian, Equifax y TransUnion). Esto te ayudar√° a identificar cualquier problema o discrepancia.\n",
            "\n",
            "5. **Contacta a tu proveedor de educaci√≥n**: Si tienes problemas con tu instituci√≥n educativa, como una transferencia o cancelaci√≥n de matr√≠cula, contacta a la oficina de asuntos estudiantiles o a la oficina de admisiones para obtener orientaci√≥n.\n",
            "\n",
            "6. **Contacta a tu empleador**: Si tu p√©rdida de beneficios est√° relacionada con tu empleo, habla con tu departamento de recursos humanos para entender c√≥mo puede afectar tu situaci√≥n laboral.\n",
            "\n",
            "7. **Considera obtener asesor√≠a legal**: Si la situaci√≥n es compleja y no puedes resolverla por tu cuenta, considera buscar asesor√≠a legal. Un abogado especializado en derecho de cr√©dito puede ayudarte a navegar por el proceso.\n",
            "\n",
            "8. **Mant√©n registros**: Mant√©n un registro de todas las comunicaciones y documentos relacionados con tu caso. Esto puede ser √∫til si necesitas proporcionar evidencia en el futuro.\n",
            "\n",
            "9. **Revisa tu plan de pago**: Si tienes un plan de pago para tu cr√©dito universitario, revisa si hay cambios necesarios en tu plan debido a la p√©rdida de beneficios.\n",
            "\n",
            "10. **Educa a tus familiares**: Si tus beneficios del cr√©dito universitario afectan a tus dependientes, aseg√∫rate de que ellos tambi√©n est√©n al tanto y tomen las medidas necesarias.\n",
            "\n",
            "Recuerda que cada situaci√≥n es √∫nica, por lo que es importante adaptar estos pasos a tu situaci√≥n espec√≠fica. La comunicaci√≥n y la acci√≥n r√°pida son clave para\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preguntas = [\n",
        "    \"¬øQu√© es Proyectate?\",\n",
        "    \"¬øQu√© dijo Valentina sobre el cr√©dito universitario?\",\n",
        "    \"¬øQu√© recomendaci√≥n dio David a los estudiantes rurales?\",\n",
        "]\n",
        "\n",
        "for pregunta in preguntas:\n",
        "    print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "    documentos = search_documents(pregunta)\n",
        "    contexto = \"\\n\\n\".join(documentos)\n",
        "    respuesta = generate_answer(pregunta, contexto)\n",
        "    print(\"Respuesta:\", respuesta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voD5RzQWkM62",
        "outputId": "2ef193f4-be8f-4e0c-d03b-a601c4026cf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Pregunta: ¬øQu√© es Proyectate?\n",
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "Respuesta: Parece que la informaci√≥n proporcionada no es suficiente para dar una respuesta precisa. \"Proyectate\" podr√≠a ser una instrucci√≥n o un t√©rmino en un contexto espec√≠fico, como un juego, una aplicaci√≥n o una conversaci√≥n particular. Si puedes proporcionar m√°s contexto o detalles, estar√© encantado de ayudarte a entender mejor lo que significa \"Proyectate\". Por favor, proporciona m√°s informaci√≥n.\n",
            "\n",
            "üîπ Pregunta: ¬øQu√© dijo Valentina sobre el cr√©dito universitario?\n",
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "Respuesta: Lo siento, pero no puedo ayudarte con eso. ¬øPodr√≠as proporcionar m√°s contexto o detalles sobre lo que dijo Valentina sobre el cr√©dito universitario? Esto me permitir√° darte una respuesta m√°s precisa.\n",
            "\n",
            "üîπ Pregunta: ¬øQu√© recomendaci√≥n dio David a los estudiantes rurales?\n",
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "Respuesta: Lo siento, pero no puedo proporcionar la recomendaci√≥n espec√≠fica de David a los estudiantes rurales sin m√°s contexto o detalles sobre la conversaci√≥n o el documento al que te refieres. Si puedes proporcionar m√°s informaci√≥n o contexto, estar√© encantado de ayudarte a encontrar la respuesta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preguntas = [\n",
        "    \"Qui√©n es Valentina Gran de Fundaci√≥n Por Una Carrera?\",\n",
        "    \"Qui√©n es David Leal de Innovacien?\",\n",
        "    \"¬øQu√© es el chat de Inteligencia artificial que se present√≥ en la conversaci√≥n?\",\n",
        "]\n",
        "\n",
        "for pregunta in preguntas:\n",
        "    print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "    documentos = search_documents(pregunta)\n",
        "    contexto = \"\\n\\n\".join(documentos)\n",
        "    respuesta = generate_answer(pregunta, contexto)\n",
        "    print(\"Respuesta:\", respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjg1tFk1lS_8",
        "outputId": "371603e8-3554-44ef-8e4f-528811cd33a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Pregunta: Qui√©n es Valentina Gran de Fundaci√≥n Por Una Carrera?\n",
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "Respuesta: Valentina Gran es una destacada defensora de la igualdad de g√©nero y la educaci√≥n en Argentina. Es conocida por su trabajo en la Fundaci√≥n Por Una Carrera (FPC), una organizaci√≥n sin fines de lucro dedicada a promover la igualdad de g√©nero en el √°mbito laboral y educativo.\n",
            "\n",
            "La Fundaci√≥n Por Una Carrera, fundada por Valentina Gran en 2006, se enfoca en la creaci√≥n de oportunidades para las mujeres en el mundo del trabajo y en la educaci√≥n. La organizaci√≥n realiza diversas actividades, como la realizaci√≥n de seminarios, talleres y programas de capacitaci√≥n, con el objetivo de empoderar a las mujeres y promover la igualdad de oportunidades.\n",
            "\n",
            "Valentina Gran ha sido una figura clave en la promoci√≥n de pol√≠ticas y programas que buscan mejorar la situaci√≥n de las mujeres en Argentina y en Latinoam√©rica. Su trabajo ha recibido reconocimiento internacional, y ha sido invitada a participar en diversos foros y eventos relacionados con la igualdad de g√©nero.\n",
            "\n",
            "Si tienes alguna pregunta espec√≠fica sobre Valentina Gran o la Fundaci√≥n Por Una Carrera, no dudes en preguntar.\n",
            "\n",
            "üîπ Pregunta: Qui√©n es David Leal de Innovacien?\n",
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "Respuesta: David Leal de Innovacien es un emprendedor y CEO de la empresa Innovacien, una startup enfocada en la tecnolog√≠a de inteligencia artificial y aprendizaje autom√°tico. Su empresa se dedica a desarrollar soluciones innovadoras para diversas industrias, utilizando la IA para mejorar procesos, optimizar operaciones y crear nuevas oportunidades de negocio. Leal ha sido reconocido por su liderazgo en el campo de la IA y por su capacidad para impulsar la transformaci√≥n digital en varios sectores. Su visi√≥n y experiencia han sido fundamentales para el crecimiento y √©xito de Innovacien.\n",
            "\n",
            "üîπ Pregunta: ¬øQu√© es el chat de Inteligencia artificial que se present√≥ en la conversaci√≥n?\n",
            "Campos disponibles: dict_keys(['@search.score', 'chunk_id', 'parent_id', 'chunk', 'title', 'text_vector'])\n",
            "Respuesta: Parece que hay un error en tu solicitud, ya que no has proporcionado el contexto o la conversaci√≥n al que te refieres. ¬øPodr√≠as proporcionar m√°s detalles o especificar qu√© chat de Inteligencia artificial te gustar√≠a saber sobre? Estar√© encantado de ayudarte una vez que tenga m√°s informaci√≥n.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_embedding(text):\n",
        "    response = client.embeddings.create(\n",
        "        model=os.environ[\"AZURE_OPENAI_EMBEDDING\"],\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n"
      ],
      "metadata": {
        "id": "9O_pg9DUo6KW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_documents_with_vectors(query, top_k=3):\n",
        "    embedding = get_query_embedding(query)\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": AZURE_SEARCH_API_KEY\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"vectorQueries\": [\n",
        "            {\n",
        "                \"vector\": embedding,\n",
        "                \"k\": top_k,\n",
        "                \"fields\": \"content\"\n",
        "            }\n",
        "        ],\n",
        "        \"select\": \"content,source,@search.score\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    results = response.json()\n",
        "    return [doc[\"content\"] for doc in results.get(\"value\", [])]\n"
      ],
      "metadata": {
        "id": "Nmab9FrEpxd_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mejorar el c√≥digo actual del cuaderno `mentoria_vocacional.ipynb`, propongo varias optimizaciones y mejoras que abordan problemas observados, mejoran la robustez, la eficiencia y la usabilidad. Las mejoras est√°n organizadas por categor√≠a, con explicaciones claras de los problemas identificados y las soluciones propuestas.\n",
        "\n",
        "## 1. Manejo de Documentos Vac√≠os y Contexto Insuficiente\n",
        "\n",
        "**Problema**: En la mayor√≠a de los ejemplos, los documentos recuperados de Azure Search est√°n vac√≠os (`contexto` vac√≠o), lo que indica que el √≠ndice no contiene datos relevantes o que las consultas no est√°n bien alineadas con el contenido indexado. Esto lleva a respuestas gen√©ricas basadas en el conocimiento del modelo en lugar de los documentos.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Validaci√≥n de Resultados de B√∫squeda**:\n",
        "   - Agregar una verificaci√≥n expl√≠cita para manejar casos donde no se recuperan documentos.\n",
        "   - Informar al usuario cuando no se encuentran resultados y sugerir reformular la consulta.\n",
        "\n",
        "   ```python\n",
        "   def search_documents(query, top_k=10):\n",
        "       ...\n",
        "       results = response.json()\n",
        "       documents = results.get(\"value\", [])\n",
        "       if not documents:\n",
        "           print(f\"No se encontraron documentos para la consulta: '{query}'\")\n",
        "           return []\n",
        "       return [doc.get(\"content\", \"\") for doc in documents]\n",
        "   ```\n",
        "\n",
        "2. **Uso de B√∫squeda Sem√°ntica**:\n",
        "   - Activar la b√∫squeda sem√°ntica (si est√° configurada en Azure Search) para mejorar la relevancia de los resultados, especialmente para consultas complejas.\n",
        "   - Modificar el payload para incluir `queryType: \"semantic\"` y una configuraci√≥n sem√°ntica.\n",
        "\n",
        "   ```python\n",
        "   payload = {\n",
        "       \"search\": query,\n",
        "       \"top\": top_k,\n",
        "       \"queryType\": \"semantic\",\n",
        "       \"semanticConfiguration\": \"default\"  # Aseg√∫rate de que est√© configurado en Azure\n",
        "   }\n",
        "   ```\n",
        "\n",
        "3. **Depuraci√≥n de Consultas**:\n",
        "   - Agregar un registro de la consulta y los documentos recuperados para facilitar la depuraci√≥n.\n",
        "   - Mostrar un resumen del contenido recuperado (por ejemplo, los primeros 100 caracteres de cada documento).\n",
        "\n",
        "   ```python\n",
        "   def search_documents(query, top_k=10):\n",
        "       ...\n",
        "       documents = [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "       print(f\"Consulta: {query}\")\n",
        "       print(f\"Documentos recuperados: {len(documents)}\")\n",
        "       for i, doc in enumerate(documents, 1):\n",
        "           print(f\"Doc {i}: {doc[:100]}...\")\n",
        "       return documents\n",
        "   ```\n",
        "\n",
        "**Beneficio**: Mejora la trazabilidad, permite al usuario entender por qu√© las respuestas no son espec√≠ficas y fomenta consultas m√°s precisas.\n",
        "\n",
        "## 2. Implementaci√≥n Completa de B√∫squeda con Vectores\n",
        "\n",
        "**Problema**: La funci√≥n `search_documents_with_vectors` est√° definida pero no se utiliza en ning√∫n ejemplo. Esto limita el aprovechamiento de b√∫squedas sem√°nticas basadas en embeddings, que podr√≠an mejorar la relevancia de los documentos recuperados.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Integrar B√∫squeda con Vectores**:\n",
        "   - Reemplazar o complementar `search_documents` con `search_documents_with_vectors` en los ejemplos, especialmente para preguntas complejas.\n",
        "   - Combinar b√∫squeda de texto y vectores (b√∫squeda h√≠brida) para maximizar la cobertura.\n",
        "\n",
        "   ```python\n",
        "   def search_documents_hybrid(query, top_k=10):\n",
        "       embedding = get_query_embedding(query)\n",
        "       url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "       headers = {\n",
        "           \"Content-Type\": \"application/json\",\n",
        "           \"api-key\": AZURE_SEARCH_API_KEY\n",
        "       }\n",
        "       payload = {\n",
        "           \"search\": query,\n",
        "           \"top\": top_k,\n",
        "           \"vectorQueries\": [\n",
        "               {\n",
        "                   \"vector\": embedding,\n",
        "                   \"k\": top_k,\n",
        "                   \"fields\": \"text_vector\"  # Aseg√∫rate de que el campo sea correcto\n",
        "               }\n",
        "           ],\n",
        "           \"select\": \"content,source,@search.score\"\n",
        "       }\n",
        "       response = requests.post(url, headers=headers, json=payload)\n",
        "       response.raise_for_status()\n",
        "       results = response.json()\n",
        "       documents = [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "       if not documents:\n",
        "           print(f\"No se encontraron documentos para la consulta: '{query}'\")\n",
        "       return documents\n",
        "   ```\n",
        "\n",
        "2. **Prueba de B√∫squeda con Vectores**:\n",
        "   - Agregar un ejemplo que use `search_documents_with_vectors` para comparar los resultados con la b√∫squeda de texto simple.\n",
        "\n",
        "   ```python\n",
        "   pregunta = \"¬øQu√© dijo Valentina sobre el financiamiento de la educaci√≥n?\"\n",
        "   print(\"\\n--- B√∫squeda con texto ---\")\n",
        "   documentos_texto = search_documents(pregunta)\n",
        "   print(\"Documentos:\", documentos_texto)\n",
        "   print(\"\\n--- B√∫squeda con vectores ---\")\n",
        "   documentos_vectores = search_documents_with_vectors(pregunta)\n",
        "   print(\"Documentos:\", documentos_vectores)\n",
        "   ```\n",
        "\n",
        "**Beneficio**: Aprovecha los embeddings para b√∫squedas sem√°nticas, mejorando la relevancia de los documentos, especialmente para consultas ambiguas o con lenguaje natural.\n",
        "\n",
        "## 3. Manejo de Errores y Robustez\n",
        "\n",
        "**Problema**: El c√≥digo no maneja bien errores potenciales, como problemas de autenticaci√≥n, √≠ndices no encontrados o fallos en la API de Azure OpenAI. Esto puede causar excepciones no controladas.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Manejo de Excepciones**:\n",
        "   - Agregar bloques `try-except` en las funciones cr√≠ticas (`search_documents`, `generate_answer`, `get_query_embedding`).\n",
        "\n",
        "   ```python\n",
        "   def search_documents(query, top_k=10):\n",
        "       try:\n",
        "           response = requests.post(url, headers=headers, json=payload)\n",
        "           response.raise_for_status()\n",
        "           results = response.json()\n",
        "           documents = [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "           if not documents:\n",
        "               print(f\"No se encontraron documentos para la consulta: '{query}'\")\n",
        "           return documents\n",
        "       except requests.exceptions.RequestException as e:\n",
        "           print(f\"Error al consultar Azure Search: {e}\")\n",
        "           return []\n",
        "       except KeyError as e:\n",
        "           print(f\"Error en la estructura de la respuesta: {e}\")\n",
        "           return []\n",
        "   ```\n",
        "\n",
        "   ```python\n",
        "   def generate_answer(question, context):\n",
        "       try:\n",
        "           response = client.chat.completions.create(...)\n",
        "           return response.choices[0].message.content\n",
        "       except Exception as e:\n",
        "           print(f\"Error al generar respuesta con OpenAI: {e}\")\n",
        "           return \"Lo siento, ocurri√≥ un error al procesar la respuesta.\"\n",
        "   ```\n",
        "\n",
        "2. **Validaci√≥n de Variables de Entorno**:\n",
        "   - Verificar que todas las variables de entorno necesarias est√©n definidas antes de usarlas.\n",
        "\n",
        "   ```python\n",
        "   required_env_vars = [\n",
        "       \"AZURE_SEARCH_API_KEY\", \"AZURE_SEARCH_ENDPOINT\", \"AZURE_SEARCH_INDEX_NAME\",\n",
        "       \"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\"\n",
        "   ]\n",
        "   for var in required_env_vars:\n",
        "       if not os.environ.get(var):\n",
        "           raise ValueError(f\"Falta la variable de entorno: {var}\")\n",
        "   ```\n",
        "\n",
        "**Beneficio**: Hace que el c√≥digo sea m√°s robusto y proporciona mensajes de error claros para facilitar la depuraci√≥n.\n",
        "\n",
        "## 4. Optimizaci√≥n del Prompt y Respuestas\n",
        "\n",
        "**Problema**: El `system_prompt` es gen√©rico y no siempre produce respuestas √≥ptimas. Adem√°s, las respuestas a veces son vagas cuando el contexto est√° vac√≠o.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Mejorar el System Prompt**:\n",
        "   - Hacer el prompt m√°s espec√≠fico para el dominio de mentor√≠a vocacional y educaci√≥n.\n",
        "   - Instruir al modelo para que indique expl√≠citamente cuando no hay contexto suficiente.\n",
        "\n",
        "   ```python\n",
        "   system_prompt = \"\"\"\n",
        "   Eres un mentor pedag√≥gico especializado en orientaci√≥n vocacional y educaci√≥n.\n",
        "   Responde de forma clara, breve y √∫til, bas√°ndote √∫nicamente en el contexto proporcionado.\n",
        "   Si el contexto es insuficiente o no contiene informaci√≥n relevante, indica que no puedes responder\n",
        "   con precisi√≥n y sugiere al usuario proporcionar m√°s detalles.\n",
        "   \"\"\"\n",
        "   ```\n",
        "\n",
        "2. **Ajustar Par√°metros del Modelo**:\n",
        "   - Experimentar con `temperature` y `top_p` para equilibrar creatividad y precisi√≥n.\n",
        "   - Aumentar `max_tokens` para respuestas m√°s detalladas si es necesario.\n",
        "\n",
        "   ```python\n",
        "   response = client.chat.completions.create(\n",
        "       model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "       messages=[...],\n",
        "       temperature=0.5,  # Ligeramente m√°s creativo pero a√∫n controlado\n",
        "       max_tokens=800,   # M√°s espacio para respuestas detalladas\n",
        "       top_p=0.9         # Controla la diversidad de las respuestas\n",
        "   )\n",
        "   ```\n",
        "\n",
        "**Beneficio**: Respuestas m√°s relevantes, concisas y alineadas con el prop√≥sito del sistema.\n",
        "\n",
        "## 5. Documentaci√≥n y Estructura del C√≥digo\n",
        "\n",
        "**Problema**: El c√≥digo carece de comentarios detallados y no est√° organizado de manera modular, lo que dificulta su mantenimiento y reutilizaci√≥n.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Agregar Docstrings y Comentarios**:\n",
        "   - Documentar cada funci√≥n con docstrings que describan par√°metros, retornos y prop√≥sito.\n",
        "   - Agregar comentarios inline para explicar pasos complejos.\n",
        "\n",
        "   ```python\n",
        "   def search_documents(query: str, top_k: int = 10) -> list:\n",
        "       \"\"\"\n",
        "       Busca documentos en Azure Cognitive Search basados en una consulta de texto.\n",
        "       \n",
        "       Args:\n",
        "           query (str): Texto de la consulta de b√∫squeda.\n",
        "           top_k (int): N√∫mero m√°ximo de documentos a recuperar (default: 10).\n",
        "       \n",
        "       Returns:\n",
        "           list: Lista de contenidos de los documentos recuperados.\n",
        "       \n",
        "       Raises:\n",
        "           requests.exceptions.RequestException: Si falla la solicitud a la API.\n",
        "       \"\"\"\n",
        "       # Construir la URL de la API\n",
        "       url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "       ...\n",
        "   ```\n",
        "\n",
        "2. **Modularizar el C√≥digo**:\n",
        "   - Separar el c√≥digo en m√≥dulos (por ejemplo, `azure_search.py`, `openai_client.py`) para mejorar la organizaci√≥n.\n",
        "   - Crear una funci√≥n principal que orqueste la ejecuci√≥n.\n",
        "\n",
        "   ```python\n",
        "   def main():\n",
        "       pregunta = \"¬øQu√© dijo Valentina sobre el financiamiento de la educaci√≥n?\"\n",
        "       documentos = search_documents(pregunta)\n",
        "       contexto = \"\\n\\n\".join(documentos)\n",
        "       respuesta = generate_answer(pregunta, contexto)\n",
        "       print(f\"Pregunta: {pregunta}\\nRespuesta: {respuesta}\")\n",
        "\n",
        "   if __name__ == \"__main__\":\n",
        "       main()\n",
        "   ```\n",
        "\n",
        "**Beneficio**: C√≥digo m√°s legible, mantenible y reutilizable.\n",
        "\n",
        "## 6. Pruebas y Validaci√≥n\n",
        "\n",
        "**Problema**: No hay pruebas automatizadas ni validaci√≥n de los resultados, lo que dificulta garantizar que el sistema funcione correctamente.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Agregar Pruebas Unitarias**:\n",
        "   - Usar `unittest` o `pytest` para probar las funciones clave.\n",
        "\n",
        "   ```python\n",
        "   import unittest\n",
        "\n",
        "   class TestMentoriaVocacional(unittest.TestCase):\n",
        "       def test_search_documents_empty(self):\n",
        "           result = search_documents(\"consulta inexistente\", top_k=1)\n",
        "           self.assertEqual(result, [], \"Deber√≠a devolver una lista vac√≠a para consultas sin resultados\")\n",
        "\n",
        "       def test_generate_answer_no_context(self):\n",
        "           result = generate_answer(\"Test\", \"\")\n",
        "           self.assertIn(\"insuficiente\", result.lower(), \"Deber√≠a indicar contexto insuficiente\")\n",
        "\n",
        "   if __name__ == \"__main__\":\n",
        "       unittest.main()\n",
        "   ```\n",
        "\n",
        "2. **Validar el √çndice de Azure Search**:\n",
        "   - Agregar una funci√≥n para verificar que el √≠ndice existe y contiene datos antes de ejecutar consultas.\n",
        "\n",
        "   ```python\n",
        "   def check_index():\n",
        "       url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}?api-version=2023-07-01-Preview\"\n",
        "       headers = {\"api-key\": AZURE_SEARCH_API_KEY}\n",
        "       try:\n",
        "           response = requests.get(url, headers=headers)\n",
        "           response.raise_for_status()\n",
        "           print(\"√çndice encontrado:\", response.json()[\"name\"])\n",
        "       except requests.exceptions.RequestException as e:\n",
        "           print(f\"Error al verificar el √≠ndice: {e}\")\n",
        "           return False\n",
        "       return True\n",
        "   ```\n",
        "\n",
        "**Beneficio**: Garantiza la fiabilidad del sistema y facilita la detecci√≥n de errores.\n",
        "\n",
        "## 7. Mejoras en la Experiencia del Usuario\n",
        "\n",
        "**Problema**: Las respuestas no siempre son √∫tiles debido a la falta de contexto, y no hay una interfaz clara para interactuar con el sistema.\n",
        "\n",
        "**Mejoras Propuestas**:\n",
        "\n",
        "1. **Interfaz Interactiva**:\n",
        "   - Crear un bucle interactivo en el cuaderno para que los usuarios ingresen preguntas din√°micamente.\n",
        "\n",
        "   ```python\n",
        "   def interactive_mode():\n",
        "       print(\"Sistema de Mentor√≠a Vocacional - Escribe 'salir' para terminar\")\n",
        "       while True:\n",
        "           pregunta = input(\"Ingresa tu pregunta: \")\n",
        "           if pregunta.lower() == \"salir\":\n",
        "               break\n",
        "           documentos = search_documents(pregunta)\n",
        "           contexto = \"\\n\\n\".join(documentos)\n",
        "           respuesta = generate_answer(pregunta, contexto)\n",
        "           print(f\"\\nRespuesta: {respuesta}\\n\")\n",
        "\n",
        "   interactive_mode()\n",
        "   ```\n",
        "\n",
        "2. **Formateo de Respuestas**:\n",
        "   - Usar Markdown o formato estructurado para presentar las respuestas de manera m√°s clara.\n",
        "\n",
        "   ```python\n",
        "   from IPython.display import display, Markdown\n",
        "\n",
        "   def display_answer(pregunta, respuesta):\n",
        "       display(Markdown(f\"**Pregunta**: {pregunta}\\n\\n**Respuesta**: {respuesta}\"))\n",
        "   ```\n",
        "\n",
        "**Beneficio**: Mejora la usabilidad y hace que el sistema sea m√°s accesible para usuarios no t√©cnicos.\n",
        "\n",
        "## Resumen de Mejoras\n",
        "\n",
        "| Categor√≠a | Mejora | Beneficio |\n",
        "|-----------|--------|-----------|\n",
        "| Manejo de Documentos | Validaci√≥n, b√∫squeda sem√°ntica, depuraci√≥n | Respuestas m√°s relevantes y trazabilidad |\n",
        "| B√∫squeda con Vectores | Integraci√≥n y b√∫squeda h√≠brida | Mejora la precisi√≥n de los resultados |\n",
        "| Robustez | Manejo de errores, validaci√≥n de variables | C√≥digo m√°s estable y mensajes claros |\n",
        "| Prompt y Respuestas | Prompt espec√≠fico, ajustes de par√°metros | Respuestas m√°s precisas y √∫tiles |\n",
        "| Documentaci√≥n | Docstrings, modularizaci√≥n | C√≥digo mantenible y reutilizable |\n",
        "| Pruebas | Unit tests, validaci√≥n de √≠ndice | Fiabilidad y detecci√≥n de errores |\n",
        "| Experiencia del Usuario | Interfaz interactiva, formateo | Mejor usabilidad y presentaci√≥n |\n",
        "\n"
      ],
      "metadata": {
        "id": "dy8s6Fw6wpgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Instalar dependencias ===\n",
        "# Nota: Descomentar la l√≠nea siguiente si necesitas instalar las dependencias\n",
        "# !pip install python-dotenv requests openai --upgrade\n",
        "\n",
        "# === 2. Importar bibliotecas y configurar entorno ===\n",
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "import unittest\n",
        "\n",
        "# Cargar variables de entorno desde el archivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Validar variables de entorno requeridas\n",
        "required_env_vars = [\n",
        "    \"AZURE_SEARCH_API_KEY\", \"AZURE_SEARCH_ENDPOINT\", \"AZURE_SEARCH_INDEX_NAME\",\n",
        "    \"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\"\n",
        "]\n",
        "for var in required_env_vars:\n",
        "    if not os.environ.get(var):\n",
        "        raise ValueError(f\"Falta la variable de entorno: {var}\")\n",
        "\n",
        "# Configuraci√≥n de Azure Cognitive Search\n",
        "AZURE_SEARCH_API_KEY = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "AZURE_SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
        "AZURE_SEARCH_INDEX_NAME = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "\n",
        "# Configuraci√≥n de Azure OpenAI\n",
        "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "\n",
        "# Inicializar cliente de Azure OpenAI\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-08-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "\n",
        "# === 3. Funci√≥n de b√∫squeda ===\n",
        "def search_documents(query: str, top_k: int = 10) -> list:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda de texto en Azure Cognitive Search.\n",
        "    Args:\n",
        "        query (str): Texto de la consulta de b√∫squeda.\n",
        "        top_k (int): N√∫mero m√°ximo de documentos a recuperar (default: 10).\n",
        "    Returns:\n",
        "        list: Lista de contenidos de los documentos recuperados.\n",
        "    Raises:\n",
        "        requests.exceptions.RequestException: Si falla la solicitud a la API.\n",
        "        KeyError: Si la respuesta tiene una estructura inesperada.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2023-07-01-Preview\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"api-key\": AZURE_SEARCH_API_KEY\n",
        "        }\n",
        "        payload = {\n",
        "            \"search\": query,\n",
        "            \"top\": top_k,\n",
        "            \"queryType\": \"semantic\",\n",
        "            \"semanticConfiguration\": \"default\",\n",
        "            \"select\": \"content,source,@search.score\"\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        results = response.json()\n",
        "        documents = [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "        # Depuraci√≥n\n",
        "        print(f\"Consulta: {query}\")\n",
        "        print(f\"Documentos recuperados: {len(documents)}\")\n",
        "        for i, doc in enumerate(documents, 1):\n",
        "            print(f\"Doc {i}: {doc[:100]}...\")\n",
        "        if not documents:\n",
        "            print(f\"No se encontraron documentos para la consulta: '{query}'\")\n",
        "        return documents\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al consultar Azure Search: {e}\")\n",
        "        return []\n",
        "    except KeyError as e:\n",
        "        print(f\"Error en la estructura de la respuesta: {e}\")\n",
        "        return []\n",
        "\n",
        "# === 4. Funci√≥n para generar respuestas ===\n",
        "def generate_answer(question: str, context: str) -> str:\n",
        "    \"\"\"\n",
        "    Genera una respuesta usando Azure OpenAI basada en una pregunta y contexto.\n",
        "    Args:\n",
        "        question (str): Pregunta del usuario.\n",
        "        context (str): Contexto recuperado de los documentos.\n",
        "    Returns:\n",
        "        str: Respuesta generada.\n",
        "    Raises:\n",
        "        Exception: Si falla la llamada a la API de OpenAI.\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "    Eres un mentor pedag√≥gico especializado en orientaci√≥n vocacional y educaci√≥n.\n",
        "    Responde de forma clara, breve y √∫til, bas√°ndote √∫nicamente en el contexto proporcionado.\n",
        "    Si el contexto es insuficiente o no contiene informaci√≥n relevante, indica que no puedes responder\n",
        "    con precisi√≥n y sugiere al usuario proporcionar m√°s detalles.\n",
        "    \"\"\"\n",
        "    user_prompt = f\"Pregunta: {question}\\n\\nContexto:\\n{context}\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_tokens=800,\n",
        "            top_p=0.9\n",
        "        )\n",
        "        return response.choices[0].message.content  # Correcci√≥n aqu√≠\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar respuesta con OpenAI: {e}\")\n",
        "        return \"Lo siento, ocurri√≥ un error al procesar la respuesta.\"\n",
        "\n",
        "# === 5. Funci√≥n para formatear respuestas ===\n",
        "def display_answer(pregunta: str, respuesta: str):\n",
        "    \"\"\"\n",
        "    Muestra la pregunta y respuesta en formato Markdown.\n",
        "    Args:\n",
        "        pregunta (str): Pregunta del usuario.\n",
        "        respuesta (str): Respuesta generada.\n",
        "    \"\"\"\n",
        "    display(Markdown(f\"**Pregunta**: {pregunta}\\n\\n**Respuesta**: {respuesta}\"))\n",
        "\n",
        "# === 6. Funci√≥n para verificar el √≠ndice ===\n",
        "def check_index() -> bool:\n",
        "    \"\"\"\n",
        "    Verifica si el √≠ndice de Azure Search existe y est√° accesible.\n",
        "    Returns:\n",
        "        bool: True si el √≠ndice es accesible, False en caso contrario.\n",
        "    \"\"\"\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}?api-version=2023-07-01-Preview\"\n",
        "    headers = {\"api-key\": AZURE_SEARCH_API_KEY}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        print(\"√çndice encontrado:\", response.json()[\"name\"])\n",
        "        return True\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al verificar el √≠ndice: {e}\")\n",
        "        return False\n",
        "\n",
        "# === 7. Modo interactivo ===\n",
        "def interactive_mode():\n",
        "    \"\"\"\n",
        "    Ejecuta un modo interactivo para que el usuario ingrese preguntas.\n",
        "    \"\"\"\n",
        "    if not check_index():\n",
        "        print(\"No se puede continuar debido a un problema con el √≠ndice.\")\n",
        "        return\n",
        "    print(\"Sistema de Mentor√≠a Vocacional - Escribe 'salir' para terminar\")\n",
        "    while True:\n",
        "        pregunta = input(\"Ingresa tu pregunta: \")\n",
        "        if pregunta.lower() == \"salir\":\n",
        "            break\n",
        "        documentos = search_documents(pregunta)\n",
        "        contexto = \"\\n\\n\".join(documentos)\n",
        "        respuesta = generate_answer(pregunta, contexto)\n",
        "        display_answer(pregunta, respuesta)\n",
        "\n",
        "# === 8. Pruebas unitarias ===\n",
        "class TestMentoriaVocacional(unittest.TestCase):\n",
        "    def test_search_documents_empty(self):\n",
        "        result = search_documents(\"consulta inexistente\", top_k=1)\n",
        "        self.assertEqual(result, [], \"Deber√≠a devolver una lista vac√≠a para consultas sin resultados\")\n",
        "\n",
        "    def test_generate_answer_no_context(self):\n",
        "        result = generate_answer(\"Test\", \"\")\n",
        "        self.assertIn(\"insuficiente\", result.lower()) or self.assertIn(\"no puedes responder\", result.lower(), \"Deber√≠a indicar contexto insuficiente\")\n",
        "\n",
        "# === 9. Ejemplo de uso ===\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Ejecuta un ejemplo de uso del sistema.\n",
        "    \"\"\"\n",
        "    if not check_index():\n",
        "        print(\"No se puede ejecutar el ejemplo debido a un problema con el √≠ndice.\")\n",
        "        return\n",
        "    preguntas = [\n",
        "        \"¬øQu√© es Proyectate?\",\n",
        "        \"¬øQu√© dijo Valentina sobre el cr√©dito universitario?\",\n",
        "        \"¬øQu√© recomendaci√≥n dio David a los estudiantes rurales?\",\n",
        "        \"Qui√©n es Valentina Gran de Fundaci√≥n Por Una Carrera?\",\n",
        "        \"Qui√©n es David Leal de Innovacien?\",\n",
        "        \"¬øQu√© debo hacer si perd√≠ mis beneficios del cr√©dito universitario?\"\n",
        "    ]\n",
        "    for pregunta in preguntas:\n",
        "        print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "        documentos = search_documents(pregunta)\n",
        "        contexto = \"\\n\\n\".join(documentos)\n",
        "        respuesta = generate_answer(pregunta, contexto)\n",
        "        display_answer(pregunta, respuesta)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar pruebas unitarias\n",
        "    unittest.main(argv=[''], exit=False)\n",
        "    # Ejecutar modo interactivo o ejemplo\n",
        "    main()\n",
        "    # interactive_mode() # Descomentar para usar el modo interactivo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14duOvMix8vD",
        "outputId": "0a0fe8b8-8a91-40bb-900c-47f915391d2b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "F.\n",
            "======================================================================\n",
            "FAIL: test_generate_answer_no_context (__main__.TestMentoriaVocacional.test_generate_answer_no_context)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2574798869.py\", line 176, in test_generate_answer_no_context\n",
            "    self.assertIn(\"insuficiente\", result.lower()) or self.assertIn(\"no puedes responder\", result.lower(), \"Deber√≠a indicar contexto insuficiente\")\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 'insuficiente' not found in 'parece que te gustar√≠a crear un contexto para un ejercicio de prueba. ¬øpodr√≠as proporcionar m√°s detalles o especificar el tema o el √°mbito sobre el cual deseas crear el contexto? por ejemplo, si est√°s interesado en un contexto para una prueba de matem√°ticas, ciencias o programaci√≥n, por favor, proporciona m√°s informaci√≥n. ¬°gracias!'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 3.383s\n",
            "\n",
            "FAILED (failures=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error al consultar Azure Search: 400 Client Error: Bad Request for url: https://search-vocatest.search.windows.net/indexes/rag-vocacional/docs/search?api-version=2023-07-01-Preview\n",
            "Error al verificar el √≠ndice: 403 Client Error: Forbidden for url: https://search-vocatest.search.windows.net/indexes/rag-vocacional?api-version=2023-07-01-Preview\n",
            "No se puede ejecutar el ejemplo debido a un problema con el √≠ndice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Instalar dependencias ===\n",
        "# Nota: Descomentar la l√≠nea siguiente si necesitas instalar las dependencias\n",
        "# !pip install python-dotenv requests openai --upgrade\n",
        "\n",
        "# === 2. Importar bibliotecas y configurar entorno ===\n",
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "import unittest\n",
        "from unittest.mock import patch, MagicMock  # Para mocks en tests\n",
        "\n",
        "# Cargar variables de entorno desde el archivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Validar variables de entorno requeridas\n",
        "required_env_vars = [\n",
        "    \"AZURE_SEARCH_API_KEY\", \"AZURE_SEARCH_ENDPOINT\", \"AZURE_SEARCH_INDEX_NAME\",\n",
        "    \"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\"\n",
        "]\n",
        "for var in required_env_vars:\n",
        "    if not os.environ.get(var):\n",
        "        raise ValueError(f\"Falta la variable de entorno: {var}\")\n",
        "\n",
        "# Configuraci√≥n de Azure Cognitive Search\n",
        "AZURE_SEARCH_API_KEY = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "AZURE_SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
        "AZURE_SEARCH_INDEX_NAME = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "\n",
        "# Configuraci√≥n de Azure OpenAI\n",
        "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "\n",
        "# Inicializar cliente de Azure OpenAI (despu√©s de las vars para evitar cached_property issues en mocks)\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-08-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "\n",
        "# === 3. Funci√≥n de b√∫squeda ===\n",
        "def search_documents(query: str, top_k: int = 10) -> list:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda de texto en Azure Cognitive Search.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2024-07-01\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"api-key\": AZURE_SEARCH_API_KEY\n",
        "        }\n",
        "        payload = {\n",
        "            \"search\": query,\n",
        "            \"top\": top_k,\n",
        "            \"queryType\": \"simple\",\n",
        "            \"select\": \"content,source,@search.score\"\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        results = response.json()\n",
        "        documents = [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "        print(f\"Consulta: {query}\")\n",
        "        print(f\"Documentos recuperados: {len(documents)}\")\n",
        "        for i, doc in enumerate(documents, 1):\n",
        "            print(f\"Doc {i}: {doc[:100]}...\")\n",
        "        if not documents:\n",
        "            print(f\"No se encontraron documentos para la consulta: '{query}'\")\n",
        "        return documents\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if e.response.status_code == 400:\n",
        "            print(f\"Error 400: Configuraci√≥n de b√∫squeda inv√°lida. Verifica si el √≠ndice soporta el queryType. Detalles: {e.response.text}\")\n",
        "        else:\n",
        "            print(f\"Error al consultar Azure Search: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado en b√∫squeda: {e}\")\n",
        "        return []\n",
        "\n",
        "# === 4. Funci√≥n para generar respuestas ===\n",
        "def generate_answer(question: str, context: str) -> str:\n",
        "    \"\"\"\n",
        "    Genera una respuesta usando Azure OpenAI basada en una pregunta y contexto.\n",
        "    \"\"\"\n",
        "    if not context.strip():\n",
        "        return \"El contexto proporcionado es insuficiente para responder con precisi√≥n. Por favor, proporciona m√°s detalles sobre tu consulta en orientaci√≥n vocacional o educaci√≥n.\"\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "    Eres un mentor pedag√≥gico especializado en orientaci√≥n vocacional y educaci√≥n.\n",
        "    Responde de forma clara, breve y √∫til, bas√°ndote √∫nicamente en el contexto proporcionado.\n",
        "    Si el contexto es insuficiente o no contiene informaci√≥n relevante, indica que no puedes responder\n",
        "    con precisi√≥n y sugiere al usuario proporcionar m√°s detalles.\n",
        "    \"\"\"\n",
        "    user_prompt = f\"Pregunta: {question}\\n\\nContexto:\\n{context}\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_tokens=800,\n",
        "            top_p=0.9\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar respuesta con OpenAI: {e}\")\n",
        "        return \"Lo siento, ocurri√≥ un error al procesar la respuesta.\"\n",
        "\n",
        "# === 5. Funci√≥n para formatear respuestas ===\n",
        "def display_answer(pregunta: str, respuesta: str):\n",
        "    \"\"\"\n",
        "    Muestra la pregunta y respuesta en formato Markdown.\n",
        "    \"\"\"\n",
        "    display(Markdown(f\"**Pregunta**: {pregunta}\\n\\n**Respuesta**: {respuesta}\"))\n",
        "\n",
        "# === 6. Funci√≥n para verificar el √≠ndice ===\n",
        "def check_index() -> bool:\n",
        "    \"\"\"\n",
        "    Verifica si el √≠ndice de Azure Search existe y est√° accesible.\n",
        "    \"\"\"\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}?api-version=2024-07-01\"\n",
        "    headers = {\"api-key\": AZURE_SEARCH_API_KEY}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 403:\n",
        "            print(\"Error 403: API key sin permisos de lectura. Regenera la key en Azure Portal (Query Keys): https://portal.azure.com/#blade/Microsoft_Azure_Search/SearchServiceMenuBlade/Keys\")\n",
        "            return False\n",
        "        response.raise_for_status()\n",
        "        print(\"√çndice encontrado:\", response.json()[\"name\"])\n",
        "        return True\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al verificar el √≠ndice: {e} (Status: {getattr(e.response, 'status_code', 'N/A')})\")\n",
        "        return False\n",
        "\n",
        "# === 7. Modo interactivo ===\n",
        "def interactive_mode():\n",
        "    \"\"\"\n",
        "    Ejecuta un modo interactivo para que el usuario ingrese preguntas.\n",
        "    \"\"\"\n",
        "    if not check_index():\n",
        "        print(\"No se puede continuar debido a un problema con el √≠ndice.\")\n",
        "        return\n",
        "    print(\"Sistema de Mentor√≠a Vocacional - Escribe 'salir' para terminar\")\n",
        "    while True:\n",
        "        pregunta = input(\"Ingresa tu pregunta: \")\n",
        "        if pregunta.lower() == \"salir\":\n",
        "            break\n",
        "        documentos = search_documents(pregunta)\n",
        "        contexto = \"\\n\\n\".join(documentos)\n",
        "        respuesta = generate_answer(pregunta, contexto)\n",
        "        display_answer(pregunta, respuesta)\n",
        "\n",
        "# === 8. Pruebas unitarias ===\n",
        "class TestMentoriaVocacional(unittest.TestCase):\n",
        "    @patch.object(client, 'chat.completions.create')  # Mock directo en la instancia client\n",
        "    def test_generate_answer_no_context(self, mock_create):\n",
        "        # Dado que el if not context.strip() se activa primero, el mock no se usa, pero lo configuramos por completitud\n",
        "        mock_response = MagicMock()\n",
        "        mock_choice = MagicMock()\n",
        "        mock_message = MagicMock()\n",
        "        mock_message.content = \"Mock respuesta con contexto insuficiente.\"\n",
        "        mock_choice.message = mock_message\n",
        "        mock_response.choices = [mock_choice]\n",
        "        mock_create.return_value = mock_response\n",
        "\n",
        "        result = generate_answer(\"Test\", \"\")\n",
        "        print(f\"Resultado de la prueba: {result}\")  # Debug para ver el mensaje fijo\n",
        "        lower_result = result.lower()\n",
        "        self.assertTrue(\n",
        "            any(phrase in lower_result for phrase in [\"insuficiente\", \"proporciona m√°s detalles\", \"orientaci√≥n vocacional\"]),\n",
        "            \"Deber√≠a indicar contexto insuficiente o sugerir m√°s detalles\"\n",
        "        )\n",
        "\n",
        "    @patch('requests.post')  # Mock de requests para evitar llamadas reales\n",
        "    def test_search_documents_empty(self, mock_post):\n",
        "        mock_response = MagicMock()\n",
        "        mock_response.status_code = 200\n",
        "        mock_response.json.return_value = {\"value\": []}\n",
        "        mock_post.return_value = mock_response\n",
        "        result = search_documents(\"consulta inexistente\", top_k=1)\n",
        "        self.assertEqual(result, [], \"Deber√≠a devolver una lista vac√≠a para consultas sin resultados\")\n",
        "\n",
        "# === 9. Ejemplo de uso ===\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Ejecuta un ejemplo de uso del sistema.\n",
        "    \"\"\"\n",
        "    if not check_index():\n",
        "        print(\"No se puede ejecutar el ejemplo debido a un problema con el √≠ndice.\")\n",
        "        print(\"Soluci√≥n: Verifica API key y configuraci√≥n sem√°ntica en Azure Portal.\")\n",
        "        return\n",
        "    preguntas = [\n",
        "        \"¬øQu√© es Proyectate?\",\n",
        "        \"¬øQu√© dijo Valentina sobre el cr√©dito universitario?\",\n",
        "        \"¬øQu√© recomendaci√≥n dio David a los estudiantes rurales?\",\n",
        "        \"Qui√©n es Valentina Gran de Fundaci√≥n Por Una Carrera?\",\n",
        "        \"Qui√©n es David Leal de Innovacien?\",\n",
        "        \"¬øQu√© debo hacer si perd√≠ mis beneficios del cr√©dito universitario?\"\n",
        "    ]\n",
        "    for pregunta in preguntas:\n",
        "        print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "        documentos = search_documents(pregunta)\n",
        "        contexto = \"\\n\\n\".join(documentos)\n",
        "        respuesta = generate_answer(pregunta, contexto)\n",
        "        display_answer(pregunta, respuesta)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar pruebas unitarias\n",
        "    unittest.main(argv=[''], exit=False, verbosity=2)\n",
        "    # Ejecutar modo interactivo o ejemplo\n",
        "    main()\n",
        "    # interactive_mode() # Descomentar para usar el modo interactivo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b2EYjV5yV_j",
        "outputId": "5b617aac-d676-4e3b-aeee-77ad1a8babf6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_generate_answer_no_context (__main__.TestMentoriaVocacional.test_generate_answer_no_context) ... ERROR\n",
            "test_search_documents_empty (__main__.TestMentoriaVocacional.test_search_documents_empty) ... ok\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_generate_answer_no_context (__main__.TestMentoriaVocacional.test_generate_answer_no_context)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/unittest/mock.py\", line 1393, in patched\n",
            "    with self.decoration_helper(patched,\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
            "    return next(self.gen)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/unittest/mock.py\", line 1375, in decoration_helper\n",
            "    arg = exit_stack.enter_context(patching)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 526, in enter_context\n",
            "    result = _enter(cm)\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/unittest/mock.py\", line 1467, in __enter__\n",
            "    original, local = self.get_original()\n",
            "                      ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/unittest/mock.py\", line 1437, in get_original\n",
            "    raise AttributeError(\n",
            "AttributeError: <openai.lib.azure.AzureOpenAI object at 0x78f36e017680> does not have the attribute 'chat.completions.create'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.005s\n",
            "\n",
            "FAILED (errors=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consulta: consulta inexistente\n",
            "Documentos recuperados: 0\n",
            "No se encontraron documentos para la consulta: 'consulta inexistente'\n",
            "Error 403: API key sin permisos de lectura. Regenera la key en Azure Portal (Query Keys): https://portal.azure.com/#blade/Microsoft_Azure_Search/SearchServiceMenuBlade/Keys\n",
            "No se puede ejecutar el ejemplo debido a un problema con el √≠ndice.\n",
            "Soluci√≥n: Verifica API key y configuraci√≥n sem√°ntica en Azure Portal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Instalar dependencias ===\n",
        "# Nota: Descomentar la l√≠nea siguiente si necesitas instalar las dependencias\n",
        "# !pip install python-dotenv requests openai --upgrade\n",
        "\n",
        "# === 2. Importar bibliotecas y configurar entorno ===\n",
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "import unittest\n",
        "from unittest.mock import patch, MagicMock\n",
        "\n",
        "# Cargar variables de entorno desde el archivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Validar variables de entorno requeridas\n",
        "required_env_vars = [\n",
        "    \"AZURE_SEARCH_API_KEY\", \"AZURE_SEARCH_ENDPOINT\", \"AZURE_SEARCH_INDEX_NAME\",\n",
        "    \"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\"\n",
        "]\n",
        "for var in required_env_vars:\n",
        "    if not os.environ.get(var):\n",
        "        raise ValueError(f\"Falta la variable de entorno: {var}\")\n",
        "\n",
        "# Configuraci√≥n de Azure Cognitive Search\n",
        "AZURE_SEARCH_API_KEY = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
        "AZURE_SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
        "AZURE_SEARCH_INDEX_NAME = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
        "\n",
        "# Configuraci√≥n de Azure OpenAI\n",
        "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "\n",
        "# Inicializar cliente de Azure OpenAI\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-08-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "\n",
        "# === 3. Funci√≥n de b√∫squeda ===\n",
        "def search_documents(query: str, top_k: int = 10) -> list:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda de texto en Azure Cognitive Search.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2024-07-01\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"api-key\": AZURE_SEARCH_API_KEY\n",
        "        }\n",
        "        payload = {\n",
        "            \"search\": query,\n",
        "            \"top\": top_k,\n",
        "            \"queryType\": \"simple\",\n",
        "            \"select\": \"content,source,@search.score\"\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        results = response.json()\n",
        "        documents = [doc.get(\"content\", \"\") for doc in results.get(\"value\", [])]\n",
        "        print(f\"Consulta: {query}\")\n",
        "        print(f\"Documentos recuperados: {len(documents)}\")\n",
        "        for i, doc in enumerate(documents, 1):\n",
        "            print(f\"Doc {i}: {doc[:100]}...\")\n",
        "        if not documents:\n",
        "            print(f\"No se encontraron documentos para la consulta: '{query}'\")\n",
        "        return documents\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if e.response.status_code == 400:\n",
        "            print(f\"Error 400: Configuraci√≥n de b√∫squeda inv√°lida. Verifica si el √≠ndice soporta el queryType. Detalles: {e.response.text}\")\n",
        "        else:\n",
        "            print(f\"Error al consultar Azure Search: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado en b√∫squeda: {e}\")\n",
        "        return []\n",
        "\n",
        "# === 4. Funci√≥n para generar respuestas ===\n",
        "def generate_answer(question: str, context: str) -> str:\n",
        "    \"\"\"\n",
        "    Genera una respuesta usando Azure OpenAI basada en una pregunta y contexto.\n",
        "    \"\"\"\n",
        "    if not context.strip():\n",
        "        return \"El contexto proporcionado es insuficiente para responder con precisi√≥n. Por favor, proporciona m√°s detalles sobre tu consulta en orientaci√≥n vocacional o educaci√≥n.\"\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "    Eres un mentor pedag√≥gico especializado en orientaci√≥n vocacional y educaci√≥n.\n",
        "    Responde de forma clara, breve y √∫til, bas√°ndote √∫nicamente en el contexto proporcionado.\n",
        "    Si el contexto es insuficiente o no contiene informaci√≥n relevante, indica que no puedes responder\n",
        "    con precisi√≥n y sugiere al usuario proporcionar m√°s detalles.\n",
        "    \"\"\"\n",
        "    user_prompt = f\"Pregunta: {question}\\n\\nContexto:\\n{context}\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_tokens=800,\n",
        "            top_p=0.9\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar respuesta con OpenAI: {e}\")\n",
        "        return \"Lo siento, ocurri√≥ un error al procesar la respuesta.\"\n",
        "\n",
        "# === 5. Funci√≥n para formatear respuestas ===\n",
        "def display_answer(pregunta: str, respuesta: str):\n",
        "    \"\"\"\n",
        "    Muestra la pregunta y respuesta en formato Markdown.\n",
        "    \"\"\"\n",
        "    display(Markdown(f\"**Pregunta**: {pregunta}\\n\\n**Respuesta**: {respuesta}\"))\n",
        "\n",
        "# === 6. Funci√≥n para verificar el √≠ndice ===\n",
        "def check_index() -> bool:\n",
        "    \"\"\"\n",
        "    Verifica si el √≠ndice de Azure Search existe y est√° accesible.\n",
        "    \"\"\"\n",
        "    url = f\"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}?api-version=2024-07-01\"\n",
        "    headers = {\"api-key\": AZURE_SEARCH_API_KEY}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 403:\n",
        "            print(\"Error 403: API key sin permisos de lectura. Regenera la key en Azure Portal (Query Keys): https://portal.azure.com/#blade/Microsoft_Azure_Search/SearchServiceMenuBlade/Keys\")\n",
        "            return False\n",
        "        response.raise_for_status()\n",
        "        print(\"√çndice encontrado:\", response.json()[\"name\"])\n",
        "        return True\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al verificar el √≠ndice: {e} (Status: {getattr(e.response, 'status_code', 'N/A')})\")\n",
        "        return False\n",
        "\n",
        "# === 7. Modo interactivo ===\n",
        "def interactive_mode():\n",
        "    \"\"\"\n",
        "    Ejecuta un modo interactivo para que el usuario ingrese preguntas.\n",
        "    \"\"\"\n",
        "    if not check_index():\n",
        "        print(\"No se puede continuar debido a un problema con el √≠ndice.\")\n",
        "        return\n",
        "    print(\"Sistema de Mentor√≠a Vocacional - Escribe 'salir' para terminar\")\n",
        "    while True:\n",
        "        pregunta = input(\"Ingresa tu pregunta: \")\n",
        "        if pregunta.lower() == \"salir\":\n",
        "            break\n",
        "        documentos = search_documents(pregunta)\n",
        "        contexto = \"\\n\\n\".join(documentos)\n",
        "        respuesta = generate_answer(pregunta, contexto)\n",
        "        display_answer(pregunta, respuesta)\n",
        "\n",
        "# === 8. Pruebas unitarias ===\n",
        "class TestMentoriaVocacional(unittest.TestCase):\n",
        "    @patch('__main__.client.chat.completions.create')  # Mock global del path completo (fix para descriptor)\n",
        "    def test_generate_answer_no_context(self, mock_create):\n",
        "        # El if activa el return fijo, mock no se usa, pero configuramos por completitud\n",
        "        mock_response = MagicMock()\n",
        "        mock_choice = MagicMock()\n",
        "        mock_message = MagicMock()\n",
        "        mock_message.content = \"Mock: Contexto insuficiente.\"\n",
        "        mock_choice.message = mock_message\n",
        "        mock_response.choices = [mock_choice]\n",
        "        mock_create.return_value = mock_response\n",
        "\n",
        "        result = generate_answer(\"Test\", \"\")\n",
        "        print(f\"Resultado de la prueba (debe ser mensaje fijo): {result[:50]}...\")  # Debug\n",
        "        lower_result = result.lower()\n",
        "        self.assertTrue(\n",
        "            any(phrase in lower_result for phrase in [\"insuficiente\", \"proporciona m√°s detalles\", \"orientaci√≥n vocacional\"]),\n",
        "            \"Deber√≠a indicar contexto insuficiente o sugerir m√°s detalles\"\n",
        "        )\n",
        "\n",
        "    @patch('__main__.client.chat.completions.create')  # Test extra: con contexto (usa mock)\n",
        "    def test_generate_answer_with_context(self, mock_create):\n",
        "        mock_response = MagicMock()\n",
        "        mock_choice = MagicMock()\n",
        "        mock_message = MagicMock()\n",
        "        mock_message.content = \"Respuesta basada en contexto proporcionado.\"\n",
        "        mock_choice.message = mock_message\n",
        "        mock_response.choices = [mock_choice]\n",
        "        mock_create.return_value = mock_response\n",
        "\n",
        "        result = generate_answer(\"Test\", \"Contexto de ejemplo.\")\n",
        "        self.assertIn(\"basada en contexto\", result.lower(), \"Deber√≠a generar respuesta con contexto\")\n",
        "\n",
        "    @patch('requests.post')  # Mock de requests para evitar llamadas reales\n",
        "    def test_search_documents_empty(self, mock_post):\n",
        "        mock_response = MagicMock()\n",
        "        mock_response.status_code = 200\n",
        "        mock_response.json.return_value = {\"value\": []}\n",
        "        mock_post.return_value = mock_response\n",
        "        result = search_documents(\"consulta inexistente\", top_k=1)\n",
        "        self.assertEqual(result, [], \"Deber√≠a devolver una lista vac√≠a para consultas sin resultados\")\n",
        "\n",
        "# === 9. Ejemplo de uso ===\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Ejecuta un ejemplo de uso del sistema.\n",
        "    \"\"\"\n",
        "    if not check_index():\n",
        "        print(\"No se puede ejecutar el ejemplo debido a un problema con el √≠ndice.\")\n",
        "        print(\"Soluci√≥n: Verifica API key y configuraci√≥n sem√°ntica en Azure Portal.\")\n",
        "        return\n",
        "    preguntas = [\n",
        "        \"¬øQu√© es Proyectate?\",\n",
        "        \"¬øQu√© dijo Valentina sobre el cr√©dito universitario?\",\n",
        "        \"¬øQu√© recomendaci√≥n dio David a los estudiantes rurales?\",\n",
        "        \"Qui√©n es Valentina Gran de Fundaci√≥n Por Una Carrera?\",\n",
        "        \"Qui√©n es David Leal de Innovacien?\",\n",
        "        \"¬øQu√© debo hacer si perd√≠ mis beneficios del cr√©dito universitario?\"\n",
        "    ]\n",
        "    for pregunta in preguntas:\n",
        "        print(f\"\\nüîπ Pregunta: {pregunta}\")\n",
        "        documentos = search_documents(pregunta)\n",
        "        contexto = \"\\n\\n\".join(documentos)\n",
        "        respuesta = generate_answer(pregunta, contexto)\n",
        "        display_answer(pregunta, respuesta)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar pruebas unitarias\n",
        "    print(\"Ejecutando pruebas unitarias...\")\n",
        "    unittest.main(argv=[''], exit=False, verbosity=2)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    # Ejecutar modo interactivo o ejemplo\n",
        "    main()\n",
        "    # interactive_mode() # Descomentar para usar el modo interactivo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8jwOwE0yoNM",
        "outputId": "18b098ec-1494-49ac-8a08-2cc7135ee10c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_generate_answer_no_context (__main__.TestMentoriaVocacional.test_generate_answer_no_context) ... ok\n",
            "test_generate_answer_with_context (__main__.TestMentoriaVocacional.test_generate_answer_with_context) ... ok\n",
            "test_search_documents_empty (__main__.TestMentoriaVocacional.test_search_documents_empty) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.008s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando pruebas unitarias...\n",
            "Resultado de la prueba (debe ser mensaje fijo): El contexto proporcionado es insuficiente para res...\n",
            "Consulta: consulta inexistente\n",
            "Documentos recuperados: 0\n",
            "No se encontraron documentos para la consulta: 'consulta inexistente'\n",
            "\n",
            "==================================================\n",
            "\n",
            "Error 403: API key sin permisos de lectura. Regenera la key en Azure Portal (Query Keys): https://portal.azure.com/#blade/Microsoft_Azure_Search/SearchServiceMenuBlade/Keys\n",
            "No se puede ejecutar el ejemplo debido a un problema con el √≠ndice.\n",
            "Soluci√≥n: Verifica API key y configuraci√≥n sem√°ntica en Azure Portal.\n"
          ]
        }
      ]
    }
  ]
}