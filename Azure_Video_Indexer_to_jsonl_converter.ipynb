{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzvS8ReG94eN6P11sfpYKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/vocacional-test/blob/main/Azure_Video_Indexer_to_jsonl_converter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicación del Código: Conversor de Azure Video Indexer a .jsonl\n",
        "\n",
        "Este documento explica el código Python diseñado para convertir archivos exportados desde Azure Video Indexer (en formato ZIP) a un archivo `.jsonl` (JSON Lines). El código está optimizado para ejecutarse en Google Colab y procesa tres tipos de artefactos: transcripciones, OCR (reconocimiento óptico de caracteres) y etiquetas visuales. A continuación, se detalla cada sección del código, su propósito y funcionamiento.\n",
        "\n",
        "---\n",
        "\n",
        "## Resumen General\n",
        "El script realiza los siguientes pasos:\n",
        "1. Permite al usuario subir un archivo ZIP exportado desde Azure Video Indexer.\n",
        "2. Extrae el contenido del ZIP a un directorio temporal.\n",
        "3. Solicita metadatos contextuales (como nombre de la clase, fecha, curso y notas).\n",
        "4. Procesa los archivos JSON de transcripción, OCR y etiquetas visuales, extrayendo información relevante.\n",
        "5. Genera un archivo `.jsonl` con los datos procesados, incluyendo los metadatos proporcionados.\n",
        "6. Descarga el archivo `.jsonl` y elimina los archivos temporales.\n",
        "\n",
        "El código incluye manejo de errores robusto, mensajes claros y codificación UTF-8 para soportar caracteres especiales. Está diseñado para ser tolerante a fallos, como la ausencia de ciertos archivos o problemas en la lectura de JSON.\n",
        "\n",
        "---\n",
        "\n",
        "## Estructura del Código\n",
        "\n",
        "### 1. Importación de Bibliotecas\n",
        "```python\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "```\n",
        "- **Propósito**: Importa las bibliotecas necesarias para:\n",
        "  - Manejo de archivos ZIP (`zipfile`).\n",
        "  - Operaciones con el sistema de archivos (`os`, `shutil`).\n",
        "  - Procesamiento de JSON (`json`).\n",
        "  - Interfaz de carga/descarga en Google Colab (`files`).\n",
        "  - Validación de fechas (`datetime`).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Subida del Archivo ZIP\n",
        "```python\n",
        "print(\"Sube el archivo ZIP exportado desde Azure Video Indexer\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    zip_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    print(f\"Error al subir el archivo ZIP: {e}\")\n",
        "    raise\n",
        "```\n",
        "- **Propósito**: Solicita al usuario que suba un archivo ZIP desde Google Colab.\n",
        "- **Funcionamiento**:\n",
        "  - Usa `files.upload()` para abrir una interfaz de carga.\n",
        "  - Extrae la ruta del archivo ZIP subido.\n",
        "  - Captura cualquier error durante la subida (por ejemplo, si no se selecciona ningún archivo) y detiene la ejecución con un mensaje claro.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Extracción del Contenido del ZIP\n",
        "```python\n",
        "extract_dir = \"azure_indexer_artifacts\"\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Archivos extraídos correctamente en: {extract_dir}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: El archivo ZIP está dañado o no es válido\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error al extraer el archivo ZIP: {e}\")\n",
        "    raise\n",
        "```\n",
        "- **Propósito**: Extrae los archivos del ZIP a un directorio temporal (`azure_indexer_artifacts`).\n",
        "- **Funcionamiento**:\n",
        "  - Usa `zipfile.ZipFile` para abrir y extraer el contenido del ZIP.\n",
        "  - Maneja errores específicos (ZIP dañado) y genéricos, mostrando mensajes descriptivos.\n",
        "  - Imprime la confirmación de la extracción exitosa.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Solicitud de Metadatos\n",
        "```python\n",
        "print(\"\\nIngresa información contextual para incluir como metadatos comunes\")\n",
        "clase = input(\"Nombre de la clase o sesión: \").strip()\n",
        "fecha = input(\"Fecha (YYYY-MM-DD): \").strip()\n",
        "curso = input(\"Curso o unidad (opcional): \").strip()\n",
        "notas = input(\"Notas adicionales (opcional): \").strip()\n",
        "\n",
        "try:\n",
        "    datetime.strptime(fecha, \"%Y-%m-%d\")\n",
        "except ValueError:\n",
        "    print(\"Error: La fecha debe estar en formato YYYY-MM-DD\")\n",
        "    raise\n",
        "```\n",
        "- **Propósito**: Recolecta metadatos contextuales que se incluirán en cada entrada del archivo `.jsonl`.\n",
        "- **Funcionamiento**:\n",
        "  - Solicita al usuario el nombre de la clase, fecha, curso (opcional) y notas (opcional).\n",
        "  - Usa `strip()` para eliminar espacios en blanco no deseados.\n",
        "  - Valida que la fecha tenga el formato `YYYY-MM-DD` usando `datetime.strptime`. Si el formato es incorrecto, lanza un error.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Funciones para Procesar Artefactos\n",
        "El código define tres funciones para procesar los archivos JSON generados por Azure Video Indexer: transcripción, OCR y etiquetas visuales. Cada función tiene una estructura similar.\n",
        "\n",
        "#### a. `extract_transcript`\n",
        "```python\n",
        "def extract_transcript(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for segment in data.get(\"recognizedPhrases\", []):\n",
        "            text = segment.get(\"display\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"transcript\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"transcript\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de transcripción: {e}\")\n",
        "        return []\n",
        "```\n",
        "- **Propósito**: Procesa el archivo de transcripción (`transcript.speechservices.json`).\n",
        "- **Funcionamiento**:\n",
        "  - Lee el archivo JSON con codificación UTF-8.\n",
        "  - Extrae los segmentos de texto de la clave `\"recognizedPhrases\"`.\n",
        "  - Crea una entrada por cada segmento de texto, incluyendo el texto, la fuente (`transcript`) y los metadatos.\n",
        "  - Si hay un error (por ejemplo, archivo corrupto o formato inesperado), muestra un mensaje y devuelve una lista vacía.\n",
        "\n",
        "#### b. `extract_ocr`\n",
        "```python\n",
        "def extract_ocr(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for region in data.get(\"regions\", []):\n",
        "            for line in region.get(\"lines\", []):\n",
        "                text = line.get(\"text\", \"\")\n",
        "                if text:\n",
        "                    entries.append({\n",
        "                        \"text\": text,\n",
        "                        \"source\": \"ocr\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"ocr\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo OCR: {e}\")\n",
        "        return []\n",
        "```\n",
        "- **Propósito**: Procesa el archivo OCR (`ocr.json`).\n",
        "- **Funcionamiento**:\n",
        "  - Lee el archivo JSON y extrae el texto de las claves `\"regions\"` y `\"lines\"`.\n",
        "  - Crea una entrada por cada línea de texto detectada, con la fuente `ocr` y los metadatos.\n",
        "  - Maneja errores de manera similar a `extract_transcript`.\n",
        "\n",
        "#### c. `extract_labels`\n",
        "```python\n",
        "def extract_labels(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for label in data.get(\"labels\", []):\n",
        "            name = label.get(\"name\", \"\")\n",
        "            if name:\n",
        "                entries.append({\n",
        "                    \"text\": name,\n",
        "                    \"source\": \"visual_label\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"label\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de etiquetas: {e}\")\n",
        "        return []\n",
        "```\n",
        "- **Propósito**: Procesa el archivo de etiquetas visuales (`labels.computervision.json`).\n",
        "- **Funcionamiento**:\n",
        "  - Extrae los nombres de etiquetas de la clave `\"labels\"`.\n",
        "  - Crea una entrada por cada etiqueta, con la fuente `visual_label` y los metadatos.\n",
        "  - Maneja errores devolviendo una lista vacía.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Procesamiento de Archivos\n",
        "```python\n",
        "jsonl_entries = []\n",
        "paths = os.listdir(extract_dir)\n",
        "\n",
        "if \"transcript.speechservices.json\" in paths:\n",
        "    jsonl_entries.extend(extract_transcript(os.path.join(extract_dir, \"transcript.speechservices.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\")\n",
        "\n",
        "if \"ocr.json\" in paths:\n",
        "    jsonl_entries.extend(extract_ocr(os.path.join(extract_dir, \"ocr.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo OCR (ocr.json)\")\n",
        "\n",
        "if \"labels.computervision.json\" in paths:\n",
        "    jsonl_entries.extend(extract_labels(os.path.join(extract_dir, \"labels.computervision.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\")\n",
        "```\n",
        "- **Propósito**: Busca y procesa los tres archivos esperados en el directorio extraído.\n",
        "- **Funcionamiento**:\n",
        "  - Revisa si cada archivo (`transcript.speechservices.json`, `ocr.json`, `labels.computervision.json`) está presente.\n",
        "  - Si un archivo existe, llama a la función correspondiente (`extract_transcript`, `extract_ocr`, `extract_labels`) y agrega las entradas a `jsonl_entries`.\n",
        "  - Si un archivo no está presente, muestra una advertencia pero continúa con los demás.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Exportación del Archivo `.jsonl`\n",
        "```python\n",
        "if jsonl_entries:\n",
        "    output_file = f\"video_indexed_{clase.replace(' ', '_')}.jsonl\"\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "            for entry in jsonl_entries:\n",
        "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "        print(f\"Archivo exportado correctamente: {output_file}\")\n",
        "        files.download(output_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el archivo .jsonl: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"Error: No se encontraron datos válidos para exportar\")\n",
        "```\n",
        "- **Propósito**: Genera y descarga el archivo `.jsonl` con los datos procesados.\n",
        "- **Funcionamiento**:\n",
        "  - Verifica si hay entradas válidas en `jsonl_entries`.\n",
        "  - Crea un archivo `.jsonl` con el nombre basado en `clase` (reemplazando espacios por guiones bajos).\n",
        "  - Escribe cada entrada como una línea JSON, usando `ensure_ascii=False` para soportar caracteres no ASCII.\n",
        "  - Descarga el archivo usando `files.download`.\n",
        "  - Si no hay entradas válidas, muestra un error. Maneja errores durante la escritura.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Limpieza\n",
        "```python\n",
        "try:\n",
        "    shutil.rmtree(extract_dir)\n",
        "    os.remove(zip_path)\n",
        "    print(\"Archivos temporales eliminados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: Error al limpiar archivos temporales: {e}\")\n",
        "```\n",
        "- **Propósito**: Elimina el directorio temporal y el archivo ZIP original.\n",
        "- **Funcionamiento**:\n",
        "  - Usa `shutil.rmtree` para eliminar el directorio `azure_indexer_artifacts`.\n",
        "  - Usa `os.remove` para eliminar el archivo ZIP.\n",
        "  - Maneja errores mostrando una advertencia, pero no detiene el programa.\n",
        "\n",
        "---\n",
        "\n",
        "## Características Clave\n",
        "- **Tolerancia a fallos**: El código maneja errores en la subida, extracción, procesamiento y escritura, mostrando mensajes claros y continuando cuando es posible.\n",
        "- **Soporte para caracteres especiales**: Usa codificación UTF-8 en todas las operaciones de archivo.\n",
        "- **Mensajes claros**: Los mensajes son descriptivos y sin emojis, con un tono profesional.\n",
        "- **Validación de datos**: Incluye verificación del formato de fecha y manejo de archivos faltantes.\n",
        "- **Compatibilidad con Google Colab**: Utiliza la API de Colab para subir y descargar archivos.\n",
        "\n",
        "---\n",
        "\n",
        "## Posibles Mejoras\n",
        "- **Validación adicional**: Verificar que el ZIP contenga al menos uno de los archivos esperados antes de procesar.\n",
        "- **Configuración flexible**: Permitir nombres de archivo personalizables o un directorio de salida configurable.\n",
        "- **Progreso visual**: Añadir una barra de progreso (por ejemplo, con `tqdm`) para archivos grandes.\n",
        "- **Logs detallados**: Guardar un registro de errores y advertencias en un archivo para depuración.\n",
        "\n",
        "---\n",
        "\n",
        "## Ejemplo de Uso\n",
        "1. Ejecuta el código en Google Colab.\n",
        "2. Sube un archivo ZIP exportado desde Azure Video Indexer.\n",
        "3. Ingresa los metadatos solicitados (clase, fecha, curso, notas).\n",
        "4. El script procesa los archivos, genera un `.jsonl` y lo descarga automáticamente.\n",
        "5. Los archivos temporales se eliminan.\n",
        "\n",
        "El archivo `.jsonl` resultante contiene entradas con el formato:\n",
        "```json\n",
        "{\"text\": \"texto extraído\", \"source\": \"transcript|ocr|visual_label\", \"metadata\": {\"clase\": \"...\", \"fecha\": \"...\", \"curso\": \"...\", \"notas\": \"...\", \"tipo\": \"...\"}}\n",
        "```\n",
        "\n",
        "Este formato es ideal para análisis posterior, como búsquedas o indexación en bases de datos."
      ],
      "metadata": {
        "id": "USKUihwxFouy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Video Indexer to .jsonl converter\n",
        "# Compatible con Google Colab\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Paso 1: Subir archivo ZIP ---\n",
        "print(\"Sube el archivo ZIP exportado desde Azure Video Indexer\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    zip_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    print(f\"Error al subir el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "extract_dir = \"azure_indexer_artifacts\"\n",
        "\n",
        "# --- Paso 2: Extraer contenido del ZIP ---\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Archivos extraídos correctamente en: {extract_dir}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: El archivo ZIP está dañado o no es válido\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error al extraer el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Paso 3: Pedir metadatos generales ---\n",
        "print(\"\\nIngresa información contextual para incluir como metadatos comunes\")\n",
        "clase = input(\"Nombre de la clase o sesión: \").strip()\n",
        "fecha = input(\"Fecha (YYYY-MM-DD): \").strip()\n",
        "curso = input(\"Curso o unidad (opcional): \").strip()\n",
        "notas = input(\"Notas adicionales (opcional): \").strip()\n",
        "\n",
        "# Validar formato de fecha\n",
        "try:\n",
        "    datetime.strptime(fecha, \"%Y-%m-%d\")\n",
        "except ValueError:\n",
        "    print(\"Error: La fecha debe estar en formato YYYY-MM-DD\")\n",
        "    raise\n",
        "\n",
        "# --- Paso 4: Funciones para procesar artefactos ---\n",
        "def extract_transcript(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for segment in data.get(\"recognizedPhrases\", []):\n",
        "            text = segment.get(\"display\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"transcript\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"transcript\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de transcripción: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_ocr(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for region in data.get(\"regions\", []):\n",
        "            for line in region.get(\"lines\", []):\n",
        "                text = line.get(\"text\", \"\")\n",
        "                if text:\n",
        "                    entries.append({\n",
        "                        \"text\": text,\n",
        "                        \"source\": \"ocr\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"ocr\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo OCR: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_labels(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for label in data.get(\"labels\", []):\n",
        "            name = label.get(\"name\", \"\")\n",
        "            if name:\n",
        "                entries.append({\n",
        "                    \"text\": name,\n",
        "                    \"source\": \"visual_label\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"label\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de etiquetas: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- Paso 5: Procesar los tres artefactos clave ---\n",
        "jsonl_entries = []\n",
        "paths = os.listdir(extract_dir)\n",
        "\n",
        "if \"transcript.speechservices.json\" in paths:\n",
        "    jsonl_entries.extend(extract_transcript(os.path.join(extract_dir, \"transcript.speechservices.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\")\n",
        "\n",
        "if \"ocr.json\" in paths:\n",
        "    jsonl_entries.extend(extract_ocr(os.path.join(extract_dir, \"ocr.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo OCR (ocr.json)\")\n",
        "\n",
        "if \"labels.computervision.json\" in paths:\n",
        "    jsonl_entries.extend(extract_labels(os.path.join(extract_dir, \"labels.computervision.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\")\n",
        "\n",
        "# --- Paso 6: Exportar .jsonl ---\n",
        "if jsonl_entries:\n",
        "    output_file = f\"video_indexed_{clase.replace(' ', '_')}.jsonl\"\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "            for entry in jsonl_entries:\n",
        "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "        print(f\"Archivo exportado correctamente: {output_file}\")\n",
        "        files.download(output_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el archivo .jsonl: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"Error: No se encontraron datos válidos para exportar\")\n",
        "\n",
        "# --- Paso 7: Limpieza ---\n",
        "try:\n",
        "    shutil.rmtree(extract_dir)\n",
        "    os.remove(zip_path)\n",
        "    print(\"Archivos temporales eliminados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: Error al limpiar archivos temporales: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "0PSHZN4HFWBV",
        "outputId": "f9c229ef-8677-4125-d769-76f392fe0a47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube el archivo ZIP exportado desde Azure Video Indexer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed93787c-52d9-4605-8800-b9bb777e7a80\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed93787c-52d9-4605-8800-b9bb777e7a80\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving live.zip to live.zip\n",
            "Archivos extraídos correctamente en: azure_indexer_artifacts\n",
            "\n",
            "Ingresa información contextual para incluir como metadatos comunes\n",
            "Nombre de la clase o sesión: Live entre Valentina Gran y David Leal en el Instagram de Fundación Por Una Carrera el 23 de junio en https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/ \n",
            "Fecha (YYYY-MM-DD): 2025-06-23\n",
            "Curso o unidad (opcional): \n",
            "Notas adicionales (opcional): \n",
            "Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\n",
            "Advertencia: No se encontró el archivo OCR (ocr.json)\n",
            "Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\n",
            "Error: No se encontraron datos válidos para exportar\n",
            "Archivos temporales eliminados correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Video Indexer to .jsonl converter\n",
        "# Compatible con Google Colab\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Paso 1: Subir archivo ZIP ---\n",
        "print(\"Sube el archivo ZIP exportado desde Azure Video Indexer\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    zip_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    print(f\"Error al subir el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "extract_dir = \"azure_indexer_artifacts\"\n",
        "\n",
        "# --- Paso 2: Extraer contenido del ZIP ---\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Archivos extraídos correctamente en: {extract_dir}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: El archivo ZIP está dañado o no es válido\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error al extraer el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "# Buscar subdirectorios si los archivos no están en la raíz (común en exportaciones de Azure)\n",
        "root_files = os.listdir(extract_dir)\n",
        "if len(root_files) == 1 and os.path.isdir(os.path.join(extract_dir, root_files[0])):\n",
        "    extract_dir = os.path.join(extract_dir, root_files[0])\n",
        "    print(f\"Archivos encontrados en subdirectorio: {extract_dir}\")\n",
        "\n",
        "# --- Paso 3: Pedir metadatos generales ---\n",
        "print(\"\\nIngresa información contextual para incluir como metadatos comunes\")\n",
        "clase = input(\"Nombre de la clase o sesión: \").strip()\n",
        "fecha = input(\"Fecha (YYYY-MM-DD): \").strip()\n",
        "curso = input(\"Curso o unidad (opcional): \").strip()\n",
        "notas = input(\"Notas adicionales (opcional): \").strip()\n",
        "\n",
        "# Validar formato de fecha\n",
        "try:\n",
        "    datetime.strptime(fecha, \"%Y-%m-%d\")\n",
        "except ValueError:\n",
        "    print(\"Error: La fecha debe estar en formato YYYY-MM-DD\")\n",
        "    raise\n",
        "\n",
        "# --- Paso 4: Funciones para procesar artefactos ---\n",
        "def extract_transcript(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for segment in data.get(\"recognizedPhrases\", []):\n",
        "            text = segment.get(\"display\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"transcript\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"transcript\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de transcripción: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_ocr(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for region in data.get(\"regions\", []):\n",
        "            for line in region.get(\"lines\", []):\n",
        "                text = line.get(\"text\", \"\")\n",
        "                if text:\n",
        "                    entries.append({\n",
        "                        \"text\": text,\n",
        "                        \"source\": \"ocr\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"ocr\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo OCR: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_labels(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for label in data.get(\"labels\", []):\n",
        "            name = label.get(\"name\", \"\")\n",
        "            if name:\n",
        "                entries.append({\n",
        "                    \"text\": name,\n",
        "                    \"source\": \"visual_label\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"label\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de etiquetas: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- Paso 5: Procesar los tres artefactos clave ---\n",
        "jsonl_entries = []\n",
        "paths = os.listdir(extract_dir)\n",
        "\n",
        "if \"transcript.speechservices.json\" in paths:\n",
        "    jsonl_entries.extend(extract_transcript(os.path.join(extract_dir, \"transcript.speechservices.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\")\n",
        "\n",
        "if \"ocr.json\" in paths:\n",
        "    jsonl_entries.extend(extract_ocr(os.path.join(extract_dir, \"ocr.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo OCR (ocr.json)\")\n",
        "\n",
        "if \"labels.computervision.json\" in paths:\n",
        "    jsonl_entries.extend(extract_labels(os.path.join(extract_dir, \"labels.computervision.json\")))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\")\n",
        "\n",
        "# --- Paso 6: Exportar .jsonl ---\n",
        "if jsonl_entries:\n",
        "    output_file = f\"video_indexed_{clase.replace(' ', '_')}.jsonl\"\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "            for entry in jsonl_entries:\n",
        "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "        print(f\"Archivo exportado correctamente: {output_file}\")\n",
        "        files.download(output_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el archivo .jsonl: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"Error: No se encontraron datos válidos para exportar\")\n",
        "\n",
        "# --- Paso 7: Limpieza ---\n",
        "try:\n",
        "    shutil.rmtree(\"azure_indexer_artifacts\")  # Limpiar el directorio raíz original\n",
        "    os.remove(zip_path)\n",
        "    print(\"Archivos temporales eliminados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: Error al limpiar archivos temporales: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "G6mItxJgHO6Z",
        "outputId": "ccaaad7b-a89e-48ac-c589-3942a174f091"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube el archivo ZIP exportado desde Azure Video Indexer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a14506e-1f19-4c3d-a581-1284d2d5bb6e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a14506e-1f19-4c3d-a581-1284d2d5bb6e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving live.zip to live.zip\n",
            "Archivos extraídos correctamente en: azure_indexer_artifacts\n",
            "\n",
            "Ingresa información contextual para incluir como metadatos comunes\n",
            "Nombre de la clase o sesión: Live entre Valentina Gran y David Leal en el Instagram de Fundación Por Una Carrera el 23 de junio en https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/\n",
            "Fecha (YYYY-MM-DD): 2025-06-23\n",
            "Curso o unidad (opcional): Uso de Proyectate info\n",
            "Notas adicionales (opcional): Este fue un live de demostracion de la aplicacion creada en conjunto \n",
            "Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\n",
            "Advertencia: No se encontró el archivo OCR (ocr.json)\n",
            "Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\n",
            "Error: No se encontraron datos válidos para exportar\n",
            "Archivos temporales eliminados correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Video Indexer to .jsonl converter\n",
        "# Compatible con Google Colab\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Paso 1: Subir archivo ZIP ---\n",
        "print(\"Sube el archivo ZIP exportado desde Azure Video Indexer\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    zip_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    print(f\"Error al subir el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "extract_dir = \"azure_indexer_artifacts\"\n",
        "\n",
        "# --- Paso 2: Extraer contenido del ZIP ---\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Archivos extraídos correctamente en: {extract_dir}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: El archivo ZIP está dañado o no es válido\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error al extraer el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Depuración: Mostrar estructura del directorio extraído ---\n",
        "print(\"\\nEstructura del directorio extraído:\")\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(f\" - {os.path.join(root, file)}\")\n",
        "\n",
        "# --- Paso 3: Pedir metadatos generales ---\n",
        "print(\"\\nIngresa información contextual para incluir como metadatos comunes\")\n",
        "clase = input(\"Nombre de la clase o sesión: \").strip()\n",
        "fecha = input(\"Fecha (YYYY-MM-DD): \").strip()\n",
        "curso = input(\"Curso o unidad (opcional): \").strip()\n",
        "notas = input(\"Notas adicionales (opcional): \").strip()\n",
        "\n",
        "# Validar formato de fecha\n",
        "try:\n",
        "    datetime.strptime(fecha, \"%Y-%m-%d\")\n",
        "except ValueError:\n",
        "    print(\"Error: La fecha debe estar en formato YYYY-MM-DD\")\n",
        "    raise\n",
        "\n",
        "# --- Paso 4: Funciones para procesar artefactos ---\n",
        "def extract_transcript(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for segment in data.get(\"CombinedRecognizedPhrases\", []):\n",
        "            text = segment.get(\"DisplayText\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"transcript\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"transcript\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de transcripción: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_ocr(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"Results\", []):\n",
        "            text = result.get(\"Ocr\", {}).get(\"content\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"ocr\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"ocr\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo OCR: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_labels(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"Results\", []):\n",
        "            for label in result.get(\"Label\", []):\n",
        "                name = label.get(\"name\", \"\")\n",
        "                if name:\n",
        "                    entries.append({\n",
        "                        \"text\": name,\n",
        "                        \"source\": \"visual_label\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"label\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de etiquetas: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_emotions(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for emotion in data:\n",
        "            text = emotion.get(\"Text\", \"\")\n",
        "            dominant_emotion = emotion.get(\"DominantEmotion\", {}).get(\"Type\", \"\")\n",
        "            if text and dominant_emotion:\n",
        "                entries.append({\n",
        "                    \"text\": f\"{text} [Dominant Emotion: {dominant_emotion}]\",\n",
        "                    \"source\": \"emotion\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"emotion\",\n",
        "                        \"dominant_emotion\": dominant_emotion\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de emociones: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_detected_objects(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"results\", []):\n",
        "            obj_type = result.get(\"type\", \"\")\n",
        "            for instance in result.get(\"instances\", []):\n",
        "                if instance.get(\"confidence\", 0) > 0:\n",
        "                    entries.append({\n",
        "                        \"text\": obj_type,\n",
        "                        \"source\": \"detected_object\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"detected_object\",\n",
        "                            \"confidence\": instance.get(\"confidence\", 0)\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de objetos detectados: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- Paso 5: Buscar y procesar los archivos clave ---\n",
        "jsonl_entries = []\n",
        "\n",
        "# Buscar archivos recursivamente\n",
        "file_paths = {}\n",
        "for root, _, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        file_paths[file] = os.path.join(root, file)\n",
        "\n",
        "# Procesar archivos si se encuentran\n",
        "if \"transcript.speechservices.json\" in file_paths:\n",
        "    print(f\"Procesando transcripción: {file_paths['transcript.speechservices.json']}\")\n",
        "    jsonl_entries.extend(extract_transcript(file_paths[\"transcript.speechservices.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\")\n",
        "\n",
        "if \"ocr.json\" in file_paths:\n",
        "    print(f\"Procesando OCR: {file_paths['ocr.json']}\")\n",
        "    jsonl_entries.extend(extract_ocr(file_paths[\"ocr.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo OCR (ocr.json)\")\n",
        "\n",
        "if \"labels.computervision.json\" in file_paths:\n",
        "    print(f\"Procesando etiquetas: {file_paths['labels.computervision.json']}\")\n",
        "    jsonl_entries.extend(extract_labels(file_paths[\"labels.computervision.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\")\n",
        "\n",
        "if \"emotions.json\" in file_paths:\n",
        "    print(f\"Procesando emociones: {file_paths['emotions.json']}\")\n",
        "    jsonl_entries.extend(extract_emotions(file_paths[\"emotions.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de emociones (emotions.json)\")\n",
        "\n",
        "if \"detectedobjects.json\" in file_paths:\n",
        "    print(f\"Procesando objetos detectados: {file_paths['detectedobjects.json']}\")\n",
        "    jsonl_entries.extend(extract_detected_objects(file_paths[\"detectedobjects.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de objetos detectados (detectedobjects.json)\")\n",
        "\n",
        "# --- Paso 6: Exportar .jsonl ---\n",
        "if jsonl_entries:\n",
        "    output_file = f\"video_indexed_{clase.replace(' ', '_')}.jsonl\"\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "            for entry in jsonl_entries:\n",
        "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "        print(f\"Archivo exportado correctamente: {output_file}\")\n",
        "        files.download(output_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el archivo .jsonl: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"Error: No se encontraron datos válidos para exportar\")\n",
        "\n",
        "# --- Paso 7: Limpieza ---\n",
        "try:\n",
        "    shutil.rmtree(\"azure_indexer_artifacts\")  # Limpiar el directorio raíz original\n",
        "    os.remove(zip_path)\n",
        "    print(\"Archivos temporales eliminados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: Error al limpiar archivos temporales: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "cJPsiY3nH5rE",
        "outputId": "b15a42ca-bb34-4728-f2ed-382ee4cc2b8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube el archivo ZIP exportado desde Azure Video Indexer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5511a4f8-ca01-4646-9b6f-51b13efda278\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5511a4f8-ca01-4646-9b6f-51b13efda278\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving live.zip to live.zip\n",
            "Archivos extraídos correctamente en: azure_indexer_artifacts\n",
            "\n",
            "Estructura del directorio extraído:\n",
            " - azure_indexer_artifacts/__MACOSX/._live\n",
            " - azure_indexer_artifacts/__MACOSX/live/._detectedobjects.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._labels.computervision.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._transcript.speechservices.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._Textual_Content_Moderation.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._ocr.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/.__KeyFrameThumbnail.zip\n",
            " - azure_indexer_artifacts/__MACOSX/live/._emotions.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._contentmoderation.json\n",
            " - azure_indexer_artifacts/live/emotions.json\n",
            " - azure_indexer_artifacts/live/Textual_Content_Moderation.json\n",
            " - azure_indexer_artifacts/live/_KeyFrameThumbnail.zip\n",
            " - azure_indexer_artifacts/live/transcript.speechservices.json\n",
            " - azure_indexer_artifacts/live/contentmoderation.json\n",
            " - azure_indexer_artifacts/live/ocr.json\n",
            " - azure_indexer_artifacts/live/detectedobjects.json\n",
            " - azure_indexer_artifacts/live/labels.computervision.json\n",
            "\n",
            "Ingresa información contextual para incluir como metadatos comunes\n",
            "Nombre de la clase o sesión: Live entre Valentina Gran y David Leal en el Instagram de Fundación Por Una Carrera el 23 de junio en https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/\n",
            "Fecha (YYYY-MM-DD): 2025-06-23\n",
            "Curso o unidad (opcional): Este fue un live de demostracion de la aplicacion creada en conjunto\n",
            "Notas adicionales (opcional): Uso de Proyectate info\n",
            "Procesando transcripción: azure_indexer_artifacts/live/transcript.speechservices.json\n",
            "Procesando OCR: azure_indexer_artifacts/live/ocr.json\n",
            "Procesando etiquetas: azure_indexer_artifacts/live/labels.computervision.json\n",
            "Procesando emociones: azure_indexer_artifacts/live/emotions.json\n",
            "Procesando objetos detectados: azure_indexer_artifacts/live/detectedobjects.json\n",
            "Error al exportar el archivo .jsonl: [Errno 2] No such file or directory: 'video_indexed_Live_entre_Valentina_Gran_y_David_Leal_en_el_Instagram_de_Fundación_Por_Una_Carrera_el_23_de_junio_en_https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/.jsonl'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'video_indexed_Live_entre_Valentina_Gran_y_David_Leal_en_el_Instagram_de_Fundación_Por_Una_Carrera_el_23_de_junio_en_https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1123139864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"video_indexed_{clase.replace(' ', '_')}.jsonl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjsonl_entries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'video_indexed_Live_entre_Valentina_Gran_y_David_Leal_en_el_Instagram_de_Fundación_Por_Una_Carrera_el_23_de_junio_en_https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/.jsonl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Video Indexer to .jsonl converter\n",
        "# Compatible con Google Colab\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# --- Paso 1: Subir archivo ZIP ---\n",
        "print(\"Sube el archivo ZIP exportado desde Azure Video Indexer\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    zip_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    print(f\"Error al subir el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "extract_dir = \"azure_indexer_artifacts\"\n",
        "\n",
        "# --- Paso 2: Extraer contenido del ZIP ---\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Archivos extraídos correctamente en: {extract_dir}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: El archivo ZIP está dañado o no es válido\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error al extraer el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Depuración: Mostrar estructura del directorio extraído ---\n",
        "print(\"\\nEstructura del directorio extraído:\")\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(f\" - {os.path.join(root, file)}\")\n",
        "\n",
        "# --- Paso 3: Pedir metadatos generales ---\n",
        "print(\"\\nIngresa información contextual para incluir como metadatos comunes\")\n",
        "clase = input(\"Nombre de la clase o sesión: \").strip()\n",
        "fecha = input(\"Fecha (YYYY-MM-DD): \").strip()\n",
        "curso = input(\"Curso o unidad (opcional): \").strip()\n",
        "notas = input(\"Notas adicionales (opcional): \").strip()\n",
        "\n",
        "# Validar formato de fecha\n",
        "try:\n",
        "    datetime.strptime(fecha, \"%Y-%m-%d\")\n",
        "except ValueError:\n",
        "    print(\"Error: La fecha debe estar en formato YYYY-MM-DD\")\n",
        "    raise\n",
        "\n",
        "# --- Paso 4: Funciones para procesar artefactos ---\n",
        "def extract_transcript(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for phrase in data.get(\"RecognizedPhrases\", []):\n",
        "            nbest = phrase.get(\"NBest\", [])\n",
        "            if nbest:\n",
        "                text = nbest[0].get(\"Display\", \"\")\n",
        "                if text:\n",
        "                    entries.append({\n",
        "                        \"text\": text,\n",
        "                        \"source\": \"transcript\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"transcript\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de transcripción: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_ocr(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"Results\", []):\n",
        "            text = result.get(\"Ocr\", {}).get(\"content\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"ocr\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"ocr\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo OCR: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_labels(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"Results\", []):\n",
        "            for label in result.get(\"Label\", []):\n",
        "                name = label.get(\"name\", \"\")\n",
        "                if name:\n",
        "                    entries.append({\n",
        "                        \"text\": name,\n",
        "                        \"source\": \"visual_label\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"label\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de etiquetas: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_emotions(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for emotion in data:\n",
        "            text = emotion.get(\"Text\", \"\")\n",
        "            dominant_emotion = emotion.get(\"DominantEmotion\", {}).get(\"Type\", \"\")\n",
        "            if text and dominant_emotion:\n",
        "                entries.append({\n",
        "                    \"text\": f\"{text} [Dominant Emotion: {dominant_emotion}]\",\n",
        "                    \"source\": \"emotion\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"emotion\",\n",
        "                        \"dominant_emotion\": dominant_emotion\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de emociones: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_detected_objects(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"results\", []):\n",
        "            obj_type = result.get(\"type\", \"\")\n",
        "            for instance in result.get(\"instances\", []):\n",
        "                if instance.get(\"confidence\", 0) > 0:\n",
        "                    entries.append({\n",
        "                        \"text\": obj_type,\n",
        "                        \"source\": \"detected_object\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"detected_object\",\n",
        "                            \"confidence\": instance.get(\"confidence\", 0)\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de objetos detectados: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- Paso 5: Buscar y procesar los archivos clave ---\n",
        "jsonl_entries = []\n",
        "\n",
        "# Buscar archivos recursivamente\n",
        "file_paths = {}\n",
        "for root, _, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        file_paths[file] = os.path.join(root, file)\n",
        "\n",
        "# Procesar archivos si se encuentran\n",
        "if \"transcript.speechservices.json\" in file_paths:\n",
        "    print(f\"Procesando transcripción: {file_paths['transcript.speechservices.json']}\")\n",
        "    jsonl_entries.extend(extract_transcript(file_paths[\"transcript.speechservices.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\")\n",
        "\n",
        "if \"ocr.json\" in file_paths:\n",
        "    print(f\"Procesando OCR: {file_paths['ocr.json']}\")\n",
        "    jsonl_entries.extend(extract_ocr(file_paths[\"ocr.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo OCR (ocr.json)\")\n",
        "\n",
        "if \"labels.computervision.json\" in file_paths:\n",
        "    print(f\"Procesando etiquetas: {file_paths['labels.computervision.json']}\")\n",
        "    jsonl_entries.extend(extract_labels(file_paths[\"labels.computervision.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\")\n",
        "\n",
        "if \"emotions.json\" in file_paths:\n",
        "    print(f\"Procesando emociones: {file_paths['emotions.json']}\")\n",
        "    jsonl_entries.extend(extract_emotions(file_paths[\"emotions.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de emociones (emotions.json)\")\n",
        "\n",
        "if \"detectedobjects.json\" in file_paths:\n",
        "    print(f\"Procesando objetos detectados: {file_paths['detectedobjects.json']}\")\n",
        "    jsonl_entries.extend(extract_detected_objects(file_paths[\"detectedobjects.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de objetos detectados (detectedobjects.json)\")\n",
        "\n",
        "# --- Paso 6: Exportar .jsonl ---\n",
        "if jsonl_entries:\n",
        "    sanitized_clase = re.sub(r'[/:*?\"<>|]', '_', clase)\n",
        "    sanitized_clase = sanitized_clase.replace(' ', '_')[:100]  # Truncar a 100 chars\n",
        "    output_file = f\"video_indexed_{sanitized_clase}.jsonl\"\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "            for entry in jsonl_entries:\n",
        "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "        print(f\"Archivo exportado correctamente: {output_file}\")\n",
        "        files.download(output_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el archivo .jsonl: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"Error: No se encontraron datos válidos para exportar\")\n",
        "\n",
        "# --- Paso 7: Limpieza ---\n",
        "try:\n",
        "    shutil.rmtree(\"azure_indexer_artifacts\")  # Limpiar el directorio raíz original\n",
        "    os.remove(zip_path)\n",
        "    print(\"Archivos temporales eliminados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: Error al limpiar archivos temporales: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "spVDhhT7I00h",
        "outputId": "cdee25ce-d598-46e5-bb23-2327279be50d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube el archivo ZIP exportado desde Azure Video Indexer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-570d1558-f535-44c7-8604-8e9debec02fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-570d1558-f535-44c7-8604-8e9debec02fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving live.zip to live (1).zip\n",
            "Archivos extraídos correctamente en: azure_indexer_artifacts\n",
            "\n",
            "Estructura del directorio extraído:\n",
            " - azure_indexer_artifacts/__MACOSX/._live\n",
            " - azure_indexer_artifacts/__MACOSX/live/._detectedobjects.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._labels.computervision.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._transcript.speechservices.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._Textual_Content_Moderation.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._ocr.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/.__KeyFrameThumbnail.zip\n",
            " - azure_indexer_artifacts/__MACOSX/live/._emotions.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._contentmoderation.json\n",
            " - azure_indexer_artifacts/live/emotions.json\n",
            " - azure_indexer_artifacts/live/Textual_Content_Moderation.json\n",
            " - azure_indexer_artifacts/live/_KeyFrameThumbnail.zip\n",
            " - azure_indexer_artifacts/live/transcript.speechservices.json\n",
            " - azure_indexer_artifacts/live/contentmoderation.json\n",
            " - azure_indexer_artifacts/live/ocr.json\n",
            " - azure_indexer_artifacts/live/detectedobjects.json\n",
            " - azure_indexer_artifacts/live/labels.computervision.json\n",
            "\n",
            "Ingresa información contextual para incluir como metadatos comunes\n",
            "Nombre de la clase o sesión: Live entre Valentina Gran y David Leal en el Instagram de Fundación Por Una Carrera el 23 de junio en https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/\n",
            "Fecha (YYYY-MM-DD): 2025-06-23\n",
            "Curso o unidad (opcional): Uso de Proyectate info\n",
            "Notas adicionales (opcional): Este fue un live de demostracion de la aplicacion creada en conjunto\n",
            "Procesando transcripción: azure_indexer_artifacts/live/transcript.speechservices.json\n",
            "Procesando OCR: azure_indexer_artifacts/live/ocr.json\n",
            "Procesando etiquetas: azure_indexer_artifacts/live/labels.computervision.json\n",
            "Procesando emociones: azure_indexer_artifacts/live/emotions.json\n",
            "Procesando objetos detectados: azure_indexer_artifacts/live/detectedobjects.json\n",
            "Archivo exportado correctamente: video_indexed_Live_entre_Valentina_Gran_y_David_Leal_en_el_Instagram_de_Fundación_Por_Una_Carrera_el_23_de_junio_e.jsonl\n",
            "Error al exportar el archivo .jsonl: 'list' object has no attribute 'download'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'download'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2509446866.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Archivo exportado correctamente: {output_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error al exportar el archivo .jsonl: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'download'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Video Indexer to .jsonl converter\n",
        "# Compatible con Google Colab\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import re\n",
        "try:\n",
        "    from google.colab import files as colab_files\n",
        "except ImportError:\n",
        "    colab_files = None\n",
        "    print(\"Advertencia: No se detectó el entorno de Google Colab. La descarga automática no estará disponible.\")\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Paso 1: Subir archivo ZIP ---\n",
        "print(\"Sube el archivo ZIP exportado desde Azure Video Indexer\")\n",
        "try:\n",
        "    uploaded = colab_files.upload() if colab_files else input(\"Sube el archivo ZIP manualmente y proporciona la ruta: \")\n",
        "    zip_path = next(iter(uploaded)) if colab_files else uploaded.strip()\n",
        "except Exception as e:\n",
        "    print(f\"Error al subir el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "extract_dir = \"azure_indexer_artifacts\"\n",
        "\n",
        "# --- Paso 2: Extraer contenido del ZIP ---\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Archivos extraídos correctamente en: {extract_dir}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: El archivo ZIP está dañado o no es válido\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error al extraer el archivo ZIP: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Depuración: Mostrar estructura del directorio extraído ---\n",
        "print(\"\\nEstructura del directorio extraído:\")\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(f\" - {os.path.join(root, file)}\")\n",
        "\n",
        "# --- Paso 3: Pedir metadatos generales ---\n",
        "print(\"\\nIngresa información contextual para incluir como metadatos comunes\")\n",
        "clase = input(\"Nombre de la clase o sesión: \").strip()\n",
        "fecha = input(\"Fecha (YYYY-MM-DD): \").strip()\n",
        "curso = input(\"Curso o unidad (opcional): \").strip()\n",
        "notas = input(\"Notas adicionales (opcional): \").strip()\n",
        "\n",
        "# Validar formato de fecha\n",
        "try:\n",
        "    datetime.strptime(fecha, \"%Y-%m-%d\")\n",
        "except ValueError:\n",
        "    print(\"Error: La fecha debe estar en formato YYYY-MM-DD\")\n",
        "    raise\n",
        "\n",
        "# --- Paso 4: Funciones para procesar artefactos ---\n",
        "def extract_transcript(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for phrase in data.get(\"RecognizedPhrases\", []):\n",
        "            nbest = phrase.get(\"NBest\", [])\n",
        "            if nbest:\n",
        "                text = nbest[0].get(\"Display\", \"\")\n",
        "                if text:\n",
        "                    entries.append({\n",
        "                        \"text\": text,\n",
        "                        \"source\": \"transcript\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"transcript\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de transcripción: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_ocr(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"Results\", []):\n",
        "            text = result.get(\"Ocr\", {}).get(\"content\", \"\")\n",
        "            if text:\n",
        "                entries.append({\n",
        "                    \"text\": text,\n",
        "                    \"source\": \"ocr\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"ocr\"\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo OCR: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_labels(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"Results\", []):\n",
        "            for label in result.get(\"Label\", []):\n",
        "                name = label.get(\"name\", \"\")\n",
        "                if name:\n",
        "                    entries.append({\n",
        "                        \"text\": name,\n",
        "                        \"source\": \"visual_label\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"label\"\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de etiquetas: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_emotions(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for emotion in data:\n",
        "            text = emotion.get(\"Text\", \"\")\n",
        "            dominant_emotion = emotion.get(\"DominantEmotion\", {}).get(\"Type\", \"\")\n",
        "            if text and dominant_emotion:\n",
        "                entries.append({\n",
        "                    \"text\": f\"{text} [Dominant Emotion: {dominant_emotion}]\",\n",
        "                    \"source\": \"emotion\",\n",
        "                    \"metadata\": {\n",
        "                        \"clase\": clase,\n",
        "                        \"fecha\": fecha,\n",
        "                        \"curso\": curso,\n",
        "                        \"notas\": notas,\n",
        "                        \"tipo\": \"emotion\",\n",
        "                        \"dominant_emotion\": dominant_emotion\n",
        "                    }\n",
        "                })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de emociones: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_detected_objects(path):\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        entries = []\n",
        "        for result in data.get(\"results\", []):\n",
        "            obj_type = result.get(\"type\", \"\")\n",
        "            for instance in result.get(\"instances\", []):\n",
        "                if instance.get(\"confidence\", 0) > 0:\n",
        "                    entries.append({\n",
        "                        \"text\": obj_type,\n",
        "                        \"source\": \"detected_object\",\n",
        "                        \"metadata\": {\n",
        "                            \"clase\": clase,\n",
        "                            \"fecha\": fecha,\n",
        "                            \"curso\": curso,\n",
        "                            \"notas\": notas,\n",
        "                            \"tipo\": \"detected_object\",\n",
        "                            \"confidence\": instance.get(\"confidence\", 0)\n",
        "                        }\n",
        "                    })\n",
        "        return entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo de objetos detectados: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- Paso 5: Buscar y procesar los archivos clave ---\n",
        "jsonl_entries = []\n",
        "\n",
        "# Buscar archivos recursivamente\n",
        "file_paths = {}\n",
        "for root, _, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        file_paths[file] = os.path.join(root, file)\n",
        "\n",
        "# Procesar archivos si se encuentran\n",
        "if \"transcript.speechservices.json\" in file_paths:\n",
        "    print(f\"Procesando transcripción: {file_paths['transcript.speechservices.json']}\")\n",
        "    jsonl_entries.extend(extract_transcript(file_paths[\"transcript.speechservices.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de transcripción (transcript.speechservices.json)\")\n",
        "\n",
        "if \"ocr.json\" in file_paths:\n",
        "    print(f\"Procesando OCR: {file_paths['ocr.json']}\")\n",
        "    jsonl_entries.extend(extract_ocr(file_paths[\"ocr.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo OCR (ocr.json)\")\n",
        "\n",
        "if \"labels.computervision.json\" in file_paths:\n",
        "    print(f\"Procesando etiquetas: {file_paths['labels.computervision.json']}\")\n",
        "    jsonl_entries.extend(extract_labels(file_paths[\"labels.computervision.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de etiquetas (labels.computervision.json)\")\n",
        "\n",
        "if \"emotions.json\" in file_paths:\n",
        "    print(f\"Procesando emociones: {file_paths['emotions.json']}\")\n",
        "    jsonl_entries.extend(extract_emotions(file_paths[\"emotions.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de emociones (emotions.json)\")\n",
        "\n",
        "if \"detectedobjects.json\" in file_paths:\n",
        "    print(f\"Procesando objetos detectados: {file_paths['detectedobjects.json']}\")\n",
        "    jsonl_entries.extend(extract_detected_objects(file_paths[\"detectedobjects.json\"]))\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró el archivo de objetos detectados (detectedobjects.json)\")\n",
        "\n",
        "# --- Paso 6: Exportar .jsonl ---\n",
        "if jsonl_entries:\n",
        "    sanitized_clase = re.sub(r'[/:*?\"<>|]', '_', clase)\n",
        "    sanitized_clase = sanitized_clase.replace(' ', '_')[:100]  # Truncar a 100 chars\n",
        "    output_file = f\"video_indexed_{sanitized_clase}.jsonl\"\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "            for entry in jsonl_entries:\n",
        "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "        print(f\"Archivo exportado correctamente: {output_file}\")\n",
        "        if colab_files:\n",
        "            try:\n",
        "                colab_files.download(output_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error al descargar el archivo .jsonl: {e}\")\n",
        "                print(f\"Por favor, descarga manualmente el archivo desde la carpeta de archivos de Colab: {output_file}\")\n",
        "        else:\n",
        "            print(f\"Descarga manualmente el archivo desde la carpeta de archivos: {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el archivo .jsonl: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"Error: No se encontraron datos válidos para exportar\")\n",
        "\n",
        "# --- Paso 7: Limpieza ---\n",
        "try:\n",
        "    shutil.rmtree(\"azure_indexer_artifacts\")  # Limpiar el directorio raíz original\n",
        "    os.remove(zip_path)\n",
        "    print(\"Archivos temporales eliminados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Advertencia: Error al limpiar archivos temporales: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "wX2f708RJWKw",
        "outputId": "cfdeb3a7-675c-4b03-f391-4d9b6d86b9dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube el archivo ZIP exportado desde Azure Video Indexer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43dba221-7a72-4a20-83cb-7626514b355d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43dba221-7a72-4a20-83cb-7626514b355d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving live.zip to live (2).zip\n",
            "Archivos extraídos correctamente en: azure_indexer_artifacts\n",
            "\n",
            "Estructura del directorio extraído:\n",
            " - azure_indexer_artifacts/__MACOSX/._live\n",
            " - azure_indexer_artifacts/__MACOSX/live/._detectedobjects.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._labels.computervision.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._transcript.speechservices.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._Textual_Content_Moderation.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._ocr.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/.__KeyFrameThumbnail.zip\n",
            " - azure_indexer_artifacts/__MACOSX/live/._emotions.json\n",
            " - azure_indexer_artifacts/__MACOSX/live/._contentmoderation.json\n",
            " - azure_indexer_artifacts/live/emotions.json\n",
            " - azure_indexer_artifacts/live/Textual_Content_Moderation.json\n",
            " - azure_indexer_artifacts/live/_KeyFrameThumbnail.zip\n",
            " - azure_indexer_artifacts/live/transcript.speechservices.json\n",
            " - azure_indexer_artifacts/live/contentmoderation.json\n",
            " - azure_indexer_artifacts/live/ocr.json\n",
            " - azure_indexer_artifacts/live/detectedobjects.json\n",
            " - azure_indexer_artifacts/live/labels.computervision.json\n",
            "\n",
            "Ingresa información contextual para incluir como metadatos comunes\n",
            "Nombre de la clase o sesión: Live entre Valentina Gran Directora ejecutiva en Fundación Por Una Carrera y David Leal Director ejecutivo de Innovacien en el Instagram de Fundación Por Una Carrera el 23 de junio en https://www.instagram.com/porunacarrera/reel/DLTQtETxUUF/\n",
            "Fecha (YYYY-MM-DD): 2025-06-23\n",
            "Curso o unidad (opcional): Uso de Proyectate info\n",
            "Notas adicionales (opcional): Este fue un live de demostracion de la aplicacion creada en conjunto\n",
            "Procesando transcripción: azure_indexer_artifacts/live/transcript.speechservices.json\n",
            "Procesando OCR: azure_indexer_artifacts/live/ocr.json\n",
            "Procesando etiquetas: azure_indexer_artifacts/live/labels.computervision.json\n",
            "Procesando emociones: azure_indexer_artifacts/live/emotions.json\n",
            "Procesando objetos detectados: azure_indexer_artifacts/live/detectedobjects.json\n",
            "Archivo exportado correctamente: video_indexed_Live_entre_Valentina_Gran_Directora_ejecutiva_en_Fundación_Por_Una_Carrera_y_David_Leal_Director_eje.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e299fb6-1a9e-4063-8ddd-c77ae61e9f6a\", \"video_indexed_Live_entre_Valentina_Gran_Directora_ejecutiva_en_Fundaci\\u00f3n_Por_Una_Carrera_y_David_Leal_Director_eje.jsonl\", 24618277)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos temporales eliminados correctamente\n"
          ]
        }
      ]
    }
  ]
}